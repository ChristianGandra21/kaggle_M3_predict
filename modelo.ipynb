{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de45c07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (646, 33)\n",
      "Test: (277, 32)\n",
      "    id  age_first_funding_year  age_last_funding_year  \\\n",
      "0  719                   10.42                  13.09   \n",
      "1  429                    3.79                   3.79   \n",
      "2  178                    0.71                   2.28   \n",
      "3  197                    3.00                   5.00   \n",
      "4  444                    0.66                   5.88   \n",
      "\n",
      "   age_first_milestone_year  age_last_milestone_year  relationships  \\\n",
      "0                      8.98                    12.72              4   \n",
      "1                       NaN                      NaN             21   \n",
      "2                      1.95                     2.28              5   \n",
      "3                      9.62                    10.39             16   \n",
      "4                      6.21                     8.61             29   \n",
      "\n",
      "   funding_rounds  funding_total_usd  milestones  is_CA  ...  is_consulting  \\\n",
      "0               3            4087500           3      1  ...              0   \n",
      "1               1           45000000           0      0  ...              0   \n",
      "2               2            5200000           2      1  ...              0   \n",
      "3               2           14500000           2      0  ...              0   \n",
      "4               5           70000000           4      1  ...              0   \n",
      "\n",
      "   is_othercategory  has_VC  has_angel has_roundA  has_roundB  has_roundC  \\\n",
      "0                 0       1          1          0           0           0   \n",
      "1                 0       0          0          0           1           0   \n",
      "2                 1       1          0          1           0           0   \n",
      "3                 0       0          1          0           1           0   \n",
      "4                 0       0          0          1           1           1   \n",
      "\n",
      "   has_roundD  avg_participants  labels  \n",
      "0           0               1.0       0  \n",
      "1           0               1.0       1  \n",
      "2           0               1.0       0  \n",
      "3           0               2.0       1  \n",
      "4           1               2.8       1  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "                id  age_first_funding_year  age_last_funding_year  \\\n",
      "count   646.000000              611.000000             637.000000   \n",
      "unique         NaN                     NaN                    NaN   \n",
      "top            NaN                     NaN                    NaN   \n",
      "freq           NaN                     NaN                    NaN   \n",
      "mean    461.577399                2.341718               4.037724   \n",
      "std     264.859464                2.468275               2.950923   \n",
      "min       1.000000                0.000000               0.000000   \n",
      "25%     233.250000                0.680000               1.870000   \n",
      "50%     459.500000                1.650000               3.610000   \n",
      "75%     692.500000                3.600000               5.590000   \n",
      "max     923.000000               21.900000              21.900000   \n",
      "\n",
      "        age_first_milestone_year  age_last_milestone_year  relationships  \\\n",
      "count                 508.000000               535.000000     646.000000   \n",
      "unique                       NaN                      NaN            NaN   \n",
      "top                          NaN                      NaN            NaN   \n",
      "freq                         NaN                      NaN            NaN   \n",
      "mean                    3.352657                 4.944729       7.948916   \n",
      "std                     2.866952                 3.213319       7.397602   \n",
      "min                     0.000000                 0.000000       0.000000   \n",
      "25%                     1.185000                 2.540000       3.000000   \n",
      "50%                     2.785000                 4.620000       6.000000   \n",
      "75%                     4.935000                 6.880000      10.000000   \n",
      "max                    24.680000                24.680000      63.000000   \n",
      "\n",
      "        funding_rounds  funding_total_usd  milestones       is_CA  ...  \\\n",
      "count       646.000000       6.460000e+02  646.000000  646.000000  ...   \n",
      "unique             NaN                NaN         NaN         NaN  ...   \n",
      "top                NaN                NaN         NaN         NaN  ...   \n",
      "freq               NaN                NaN         NaN         NaN  ...   \n",
      "mean          2.351393       2.949633e+07    1.913313    0.546440  ...   \n",
      "std           1.357856       2.261999e+08    1.337095    0.498224  ...   \n",
      "min           1.000000       1.100000e+04    0.000000    0.000000  ...   \n",
      "25%           1.000000       3.000000e+06    1.000000    0.000000  ...   \n",
      "50%           2.000000       1.020000e+07    2.000000    1.000000  ...   \n",
      "75%           3.000000       2.587500e+07    3.000000    1.000000  ...   \n",
      "max           8.000000       5.700000e+09    6.000000    1.000000  ...   \n",
      "\n",
      "        is_consulting  is_othercategory      has_VC   has_angel  has_roundA  \\\n",
      "count      646.000000        646.000000  646.000000  646.000000  646.000000   \n",
      "unique            NaN               NaN         NaN         NaN         NaN   \n",
      "top               NaN               NaN         NaN         NaN         NaN   \n",
      "freq              NaN               NaN         NaN         NaN         NaN   \n",
      "mean         0.003096          0.304954    0.329721    0.260062    0.515480   \n",
      "std          0.055598          0.460745    0.470476    0.439008    0.500148   \n",
      "min          0.000000          0.000000    0.000000    0.000000    0.000000   \n",
      "25%          0.000000          0.000000    0.000000    0.000000    0.000000   \n",
      "50%          0.000000          0.000000    0.000000    0.000000    1.000000   \n",
      "75%          0.000000          1.000000    1.000000    1.000000    1.000000   \n",
      "max          1.000000          1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "        has_roundB  has_roundC  has_roundD  avg_participants      labels  \n",
      "count   646.000000  646.000000  646.000000        646.000000  646.000000  \n",
      "unique         NaN         NaN         NaN               NaN         NaN  \n",
      "top            NaN         NaN         NaN               NaN         NaN  \n",
      "freq           NaN         NaN         NaN               NaN         NaN  \n",
      "mean      0.419505    0.235294    0.091331          2.848655    0.647059  \n",
      "std       0.493860    0.424511    0.288303          1.894050    0.478255  \n",
      "min       0.000000    0.000000    0.000000          1.000000    0.000000  \n",
      "25%       0.000000    0.000000    0.000000          1.500000    0.000000  \n",
      "50%       0.000000    0.000000    0.000000          2.333300    1.000000  \n",
      "75%       1.000000    0.000000    0.000000          4.000000    1.000000  \n",
      "max       1.000000    1.000000    1.000000         16.000000    1.000000  \n",
      "\n",
      "[11 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Carregar datasets\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Ver dimens√µes\n",
    "print(\"Train:\", train.shape)\n",
    "print(\"Test:\", test.shape)\n",
    "\n",
    "# Olhar primeiras linhas\n",
    "print(train.head())\n",
    "\n",
    "# Ver estat√≠sticas gerais\n",
    "print(train.describe(include=\"all\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "362ccb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INFORMA√á√ïES GERAIS ===\n",
      "Train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 646 entries, 0 to 645\n",
      "Data columns (total 33 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   id                        646 non-null    int64  \n",
      " 1   age_first_funding_year    611 non-null    float64\n",
      " 2   age_last_funding_year     637 non-null    float64\n",
      " 3   age_first_milestone_year  508 non-null    float64\n",
      " 4   age_last_milestone_year   535 non-null    float64\n",
      " 5   relationships             646 non-null    int64  \n",
      " 6   funding_rounds            646 non-null    int64  \n",
      " 7   funding_total_usd         646 non-null    int64  \n",
      " 8   milestones                646 non-null    int64  \n",
      " 9   is_CA                     646 non-null    int64  \n",
      " 10  is_NY                     646 non-null    int64  \n",
      " 11  is_MA                     646 non-null    int64  \n",
      " 12  is_TX                     646 non-null    int64  \n",
      " 13  is_otherstate             646 non-null    int64  \n",
      " 14  category_code             646 non-null    object \n",
      " 15  is_software               646 non-null    int64  \n",
      " 16  is_web                    646 non-null    int64  \n",
      " 17  is_mobile                 646 non-null    int64  \n",
      " 18  is_enterprise             646 non-null    int64  \n",
      " 19  is_advertising            646 non-null    int64  \n",
      " 20  is_gamesvideo             646 non-null    int64  \n",
      " 21  is_ecommerce              646 non-null    int64  \n",
      " 22  is_biotech                646 non-null    int64  \n",
      " 23  is_consulting             646 non-null    int64  \n",
      " 24  is_othercategory          646 non-null    int64  \n",
      " 25  has_VC                    646 non-null    int64  \n",
      " 26  has_angel                 646 non-null    int64  \n",
      " 27  has_roundA                646 non-null    int64  \n",
      " 28  has_roundB                646 non-null    int64  \n",
      " 29  has_roundC                646 non-null    int64  \n",
      " 30  has_roundD                646 non-null    int64  \n",
      " 31  avg_participants          646 non-null    float64\n",
      " 32  labels                    646 non-null    int64  \n",
      "dtypes: float64(5), int64(27), object(1)\n",
      "memory usage: 166.7+ KB\n",
      "None\n",
      "\n",
      "Test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 277 entries, 0 to 276\n",
      "Data columns (total 32 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   id                        277 non-null    int64  \n",
      " 1   age_first_funding_year    266 non-null    float64\n",
      " 2   age_last_funding_year     273 non-null    float64\n",
      " 3   age_first_milestone_year  217 non-null    float64\n",
      " 4   age_last_milestone_year   224 non-null    float64\n",
      " 5   relationships             277 non-null    int64  \n",
      " 6   funding_rounds            277 non-null    int64  \n",
      " 7   funding_total_usd         277 non-null    int64  \n",
      " 8   milestones                277 non-null    int64  \n",
      " 9   is_CA                     277 non-null    int64  \n",
      " 10  is_NY                     277 non-null    int64  \n",
      " 11  is_MA                     277 non-null    int64  \n",
      " 12  is_TX                     277 non-null    int64  \n",
      " 13  is_otherstate             277 non-null    int64  \n",
      " 14  category_code             277 non-null    object \n",
      " 15  is_software               277 non-null    int64  \n",
      " 16  is_web                    277 non-null    int64  \n",
      " 17  is_mobile                 277 non-null    int64  \n",
      " 18  is_enterprise             277 non-null    int64  \n",
      " 19  is_advertising            277 non-null    int64  \n",
      " 20  is_gamesvideo             277 non-null    int64  \n",
      " 21  is_ecommerce              277 non-null    int64  \n",
      " 22  is_biotech                277 non-null    int64  \n",
      " 23  is_consulting             277 non-null    int64  \n",
      " 24  is_othercategory          277 non-null    int64  \n",
      " 25  has_VC                    277 non-null    int64  \n",
      " 26  has_angel                 277 non-null    int64  \n",
      " 27  has_roundA                277 non-null    int64  \n",
      " 28  has_roundB                277 non-null    int64  \n",
      " 29  has_roundC                277 non-null    int64  \n",
      " 30  has_roundD                277 non-null    int64  \n",
      " 31  avg_participants          277 non-null    float64\n",
      "dtypes: float64(5), int64(26), object(1)\n",
      "memory usage: 69.4+ KB\n",
      "None\n",
      "\n",
      "=== VALORES AUSENTES ===\n",
      "Train - valores nulos:\n",
      "id                            0\n",
      "age_first_funding_year       35\n",
      "age_last_funding_year         9\n",
      "age_first_milestone_year    138\n",
      "age_last_milestone_year     111\n",
      "relationships                 0\n",
      "funding_rounds                0\n",
      "funding_total_usd             0\n",
      "milestones                    0\n",
      "is_CA                         0\n",
      "is_NY                         0\n",
      "is_MA                         0\n",
      "is_TX                         0\n",
      "is_otherstate                 0\n",
      "category_code                 0\n",
      "is_software                   0\n",
      "is_web                        0\n",
      "is_mobile                     0\n",
      "is_enterprise                 0\n",
      "is_advertising                0\n",
      "is_gamesvideo                 0\n",
      "is_ecommerce                  0\n",
      "is_biotech                    0\n",
      "is_consulting                 0\n",
      "is_othercategory              0\n",
      "has_VC                        0\n",
      "has_angel                     0\n",
      "has_roundA                    0\n",
      "has_roundB                    0\n",
      "has_roundC                    0\n",
      "has_roundD                    0\n",
      "avg_participants              0\n",
      "labels                        0\n",
      "dtype: int64\n",
      "\n",
      "Test - valores nulos:\n",
      "id                           0\n",
      "age_first_funding_year      11\n",
      "age_last_funding_year        4\n",
      "age_first_milestone_year    60\n",
      "age_last_milestone_year     53\n",
      "relationships                0\n",
      "funding_rounds               0\n",
      "funding_total_usd            0\n",
      "milestones                   0\n",
      "is_CA                        0\n",
      "is_NY                        0\n",
      "is_MA                        0\n",
      "is_TX                        0\n",
      "is_otherstate                0\n",
      "category_code                0\n",
      "is_software                  0\n",
      "is_web                       0\n",
      "is_mobile                    0\n",
      "is_enterprise                0\n",
      "is_advertising               0\n",
      "is_gamesvideo                0\n",
      "is_ecommerce                 0\n",
      "is_biotech                   0\n",
      "is_consulting                0\n",
      "is_othercategory             0\n",
      "has_VC                       0\n",
      "has_angel                    0\n",
      "has_roundA                   0\n",
      "has_roundB                   0\n",
      "has_roundC                   0\n",
      "has_roundD                   0\n",
      "avg_participants             0\n",
      "dtype: int64\n",
      "\n",
      "=== DUPLICATAS ===\n",
      "Train duplicatas: 0\n",
      "Test duplicatas: 0\n"
     ]
    }
   ],
   "source": [
    "# AN√ÅLISE EXPLORAT√ìRIA INICIAL\n",
    "# Verificar informa√ß√µes gerais dos dados\n",
    "print(\"=== INFORMA√á√ïES GERAIS ===\")\n",
    "print(\"Train info:\")\n",
    "print(train.info())\n",
    "print(\"\\nTest info:\")\n",
    "print(test.info())\n",
    "\n",
    "# Verificar valores ausentes\n",
    "print(\"\\n=== VALORES AUSENTES ===\")\n",
    "print(\"Train - valores nulos:\")\n",
    "print(train.isnull().sum())\n",
    "print(\"\\nTest - valores nulos:\")\n",
    "print(test.isnull().sum())\n",
    "\n",
    "# Verificar duplicatas\n",
    "print(\"\\n=== DUPLICATAS ===\")\n",
    "print(f\"Train duplicatas: {train.duplicated().sum()}\")\n",
    "print(f\"Test duplicatas: {test.duplicated().sum()}\")\n",
    "\n",
    "# Analisar a vari√°vel target (se existir)\n",
    "if 'target' in train.columns or 'success' in train.columns:\n",
    "    target_col = 'target' if 'target' in train.columns else 'success'\n",
    "    print(f\"\\n=== DISTRIBUI√á√ÉO DO TARGET ({target_col}) ===\")\n",
    "    print(train[target_col].value_counts())\n",
    "    print(f\"Propor√ß√£o: {train[target_col].value_counts(normalize=True)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4252d446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TIPOS DE COLUNAS ===\n",
      "Colunas num√©ricas: ['id', 'age_first_funding_year', 'age_last_funding_year', 'age_first_milestone_year', 'age_last_milestone_year', 'relationships', 'funding_rounds', 'funding_total_usd', 'milestones', 'is_CA', 'is_NY', 'is_MA', 'is_TX', 'is_otherstate', 'is_software', 'is_web', 'is_mobile', 'is_enterprise', 'is_advertising', 'is_gamesvideo', 'is_ecommerce', 'is_biotech', 'is_consulting', 'is_othercategory', 'has_VC', 'has_angel', 'has_roundA', 'has_roundB', 'has_roundC', 'has_roundD', 'avg_participants', 'labels']\n",
      "Colunas categ√≥ricas: ['category_code']\n"
     ]
    }
   ],
   "source": [
    "#LIMPEZA E PROCESSAMENTO DOS DADOS\n",
    "\n",
    "# 1. Remover duplicatas (se houver)\n",
    "train = train.drop_duplicates()\n",
    "test = test.drop_duplicates()\n",
    "\n",
    "# 2. Identificar tipos de colunas\n",
    "print(\"\\n=== TIPOS DE COLUNAS ===\")\n",
    "numerical_cols = train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Colunas num√©ricas: {numerical_cols}\")\n",
    "print(f\"Colunas categ√≥ricas: {categorical_cols}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9107c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tratamento de valores ausentes\n",
    "def tratar_valores_ausentes(df, is_train=True):\n",
    "    \"\"\"Fun√ß√£o para tratar valores ausentes\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Para colunas num√©ricas: preencher com mediana\n",
    "    for col in numerical_cols:\n",
    "        if col in df_clean.columns and df_clean[col].isnull().sum() > 0:\n",
    "            df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "    \n",
    "    # Para colunas categ√≥ricas: preencher com moda ou 'Unknown'\n",
    "    for col in categorical_cols:\n",
    "        if col in df_clean.columns and df_clean[col].isnull().sum() > 0:\n",
    "            # Se for poucas categorias, usar moda; sen√£o usar 'Unknown'\n",
    "            if df_clean[col].nunique() < 20:\n",
    "                df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
    "            else:\n",
    "                df_clean[col].fillna('Unknown', inplace=True)\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Aplicar tratamento\n",
    "train_clean = tratar_valores_ausentes(train, is_train=True)\n",
    "test_clean = tratar_valores_ausentes(test, is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "facfcc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OUTLIERS DETECTADOS ===\n",
      "id: 0 outliers (0.00%)\n",
      "age_first_funding_year: 20 outliers (3.10%)\n",
      "age_last_funding_year: 11 outliers (1.70%)\n",
      "age_first_milestone_year: 41 outliers (6.35%)\n",
      "age_last_milestone_year: 22 outliers (3.41%)\n",
      "relationships: 47 outliers (7.28%)\n",
      "funding_rounds: 10 outliers (1.55%)\n",
      "funding_total_usd: 50 outliers (7.74%)\n",
      "milestones: 0 outliers (0.00%)\n",
      "is_CA: 0 outliers (0.00%)\n",
      "is_NY: 71 outliers (10.99%)\n",
      "is_MA: 61 outliers (9.44%)\n",
      "is_TX: 24 outliers (3.72%)\n",
      "is_otherstate: 136 outliers (21.05%)\n",
      "is_software: 105 outliers (16.25%)\n",
      "is_web: 97 outliers (15.02%)\n",
      "is_mobile: 65 outliers (10.06%)\n",
      "is_enterprise: 53 outliers (8.20%)\n",
      "is_advertising: 45 outliers (6.97%)\n",
      "is_gamesvideo: 37 outliers (5.73%)\n",
      "is_ecommerce: 20 outliers (3.10%)\n",
      "is_biotech: 25 outliers (3.87%)\n",
      "is_consulting: 2 outliers (0.31%)\n",
      "is_othercategory: 0 outliers (0.00%)\n",
      "has_VC: 0 outliers (0.00%)\n",
      "has_angel: 0 outliers (0.00%)\n",
      "has_roundA: 0 outliers (0.00%)\n",
      "has_roundB: 0 outliers (0.00%)\n",
      "has_roundC: 152 outliers (23.53%)\n",
      "has_roundD: 59 outliers (9.13%)\n",
      "avg_participants: 19 outliers (2.94%)\n",
      "labels: 0 outliers (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# 4. An√°lise de outliers (para colunas num√©ricas)\n",
    "def detectar_outliers(df, cols):\n",
    "    \"\"\"Detecta outliers usando IQR\"\"\"\n",
    "    outliers_info = {}\n",
    "    \n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "            outliers_info[col] = {\n",
    "                'count': len(outliers),\n",
    "                'percentage': len(outliers) / len(df) * 100,\n",
    "                'bounds': (lower_bound, upper_bound)\n",
    "            }\n",
    "    \n",
    "    return outliers_info\n",
    "\n",
    "# Detectar outliers\n",
    "outliers_train = detectar_outliers(train_clean, numerical_cols)\n",
    "print(\"\\n=== OUTLIERS DETECTADOS ===\")\n",
    "for col, info in outliers_train.items():\n",
    "    print(f\"{col}: {info['count']} outliers ({info['percentage']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "54665139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando coluna: category_code\n",
      "  ‚Üí Label Encoding (34 categorias)\n",
      "    ‚ö†Ô∏è  Categorias novas no test: {'hospitality'}\n",
      "    üìù Adicionadas 5 linhas 'Unknown' ao train\n"
     ]
    }
   ],
   "source": [
    "# 5. Codifica√ß√£o de vari√°veis categ√≥ricas - VERS√ÉO CORRIGIDA\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "def processar_categoricas(train_df, test_df, categorical_columns):\n",
    "    \"\"\"Processa vari√°veis categ√≥ricas - vers√£o que lida com categorias novas no test\"\"\"\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        if col in train_processed.columns:\n",
    "            print(f\"\\nProcessando coluna: {col}\")\n",
    "            \n",
    "            # Se poucas categorias, usar One-Hot Encoding\n",
    "            if train_processed[col].nunique() <= 10:\n",
    "                print(f\"  ‚Üí One-Hot Encoding ({train_processed[col].nunique()} categorias)\")\n",
    "                \n",
    "                # Identificar todas as categorias √∫nicas entre train e test\n",
    "                all_categories = set(train_processed[col].unique()) | set(test_processed[col].unique())\n",
    "                \n",
    "                # One-Hot Encoding\n",
    "                train_dummies = pd.get_dummies(train_processed[col], prefix=col)\n",
    "                test_dummies = pd.get_dummies(test_processed[col], prefix=col)\n",
    "                \n",
    "                # Garantir mesmas colunas em train e test\n",
    "                for category in all_categories:\n",
    "                    dummy_col = f\"{col}_{category}\"\n",
    "                    if dummy_col not in train_dummies.columns:\n",
    "                        train_dummies[dummy_col] = 0\n",
    "                    if dummy_col not in test_dummies.columns:\n",
    "                        test_dummies[dummy_col] = 0\n",
    "                \n",
    "                # Ordenar colunas para garantir mesma ordem\n",
    "                dummy_columns = sorted(train_dummies.columns)\n",
    "                train_dummies = train_dummies[dummy_columns]\n",
    "                test_dummies = test_dummies[dummy_columns]\n",
    "                \n",
    "                # Remover coluna original e adicionar dummies\n",
    "                train_processed = train_processed.drop(col, axis=1)\n",
    "                test_processed = test_processed.drop(col, axis=1)\n",
    "                train_processed = pd.concat([train_processed, train_dummies], axis=1)\n",
    "                test_processed = pd.concat([test_processed, test_dummies], axis=1)\n",
    "            \n",
    "            else:\n",
    "                print(f\"  ‚Üí Label Encoding ({train_processed[col].nunique()} categorias)\")\n",
    "                \n",
    "                # CORRE√á√ÉO ROBUSTA: Lidar com categorias novas no test\n",
    "                # 1. Converter para string primeiro\n",
    "                train_processed[col] = train_processed[col].astype(str)\n",
    "                test_processed[col] = test_processed[col].astype(str)\n",
    "                \n",
    "                # 2. Obter todas as categorias √∫nicas\n",
    "                train_categories = set(train_processed[col].unique())\n",
    "                test_categories = set(test_processed[col].unique())\n",
    "                \n",
    "                # 3. Categorias que est√£o no test mas n√£o no train\n",
    "                new_categories = test_categories - train_categories\n",
    "                if new_categories:\n",
    "                    print(f\"    ‚ö†Ô∏è  Categorias novas no test: {new_categories}\")\n",
    "                    # Mapear categorias novas para 'Unknown'\n",
    "                    for new_cat in new_categories:\n",
    "                        test_processed.loc[test_processed[col] == new_cat, col] = 'Unknown'\n",
    "                    \n",
    "                    # ADICIONANDO 'Unknown' ao train se necess√°rio\n",
    "                    if 'Unknown' not in train_categories:\n",
    "                        # Adicionar 'Unknown' a algumas linhas do train\n",
    "                        n_unknown = min(5, len(train_processed) // 100)  # 1% ou 5 linhas, o que for menor\n",
    "                        unknown_indices = train_processed.sample(n=n_unknown).index\n",
    "                        train_processed.loc[unknown_indices, col] = 'Unknown'\n",
    "                        print(f\"    üìù Adicionadas {n_unknown} linhas 'Unknown' ao train\")\n",
    "                \n",
    "                # 4. Aplicar Label Encoding com tratamento de erro\n",
    "                try:\n",
    "                    le = LabelEncoder()\n",
    "                    train_processed[col] = le.fit_transform(train_processed[col])\n",
    "                    test_processed[col] = le.transform(test_processed[col])\n",
    "                except ValueError as e:\n",
    "                    print(f\"    üö® Erro no Label Encoding para {col}: {e}\")\n",
    "                    # Fallback: usar One-Hot mesmo com muitas categorias\n",
    "                    print(f\"    üîÑ Usando One-Hot como fallback\")\n",
    "                    train_dummies = pd.get_dummies(train_processed[col], prefix=col)\n",
    "                    test_dummies = pd.get_dummies(test_processed[col], prefix=col)\n",
    "                    \n",
    "                    # Garantir mesmas colunas\n",
    "                    all_columns = set(train_dummies.columns) | set(test_dummies.columns)\n",
    "                    for dummy_col in all_columns:\n",
    "                        if dummy_col not in train_dummies.columns:\n",
    "                            train_dummies[dummy_col] = 0\n",
    "                        if dummy_col not in test_dummies.columns:\n",
    "                            test_dummies[dummy_col] = 0\n",
    "                    \n",
    "                    # Substituir coluna\n",
    "                    train_processed = train_processed.drop(col, axis=1)\n",
    "                    test_processed = test_processed.drop(col, axis=1)\n",
    "                    train_processed = pd.concat([train_processed, train_dummies], axis=1)\n",
    "                    test_processed = pd.concat([test_processed, test_dummies], axis=1)\n",
    "    \n",
    "    return train_processed, test_processed\n",
    "\n",
    "# Aplicar processamento categ√≥rico com corre√ß√£o\n",
    "train_processed, test_processed = processar_categoricas(train_clean, test_clean, categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d6c6af23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas num√©ricas para normalizar: ['id', 'age_first_funding_year', 'age_last_funding_year', 'age_first_milestone_year', 'age_last_milestone_year', 'relationships', 'funding_rounds', 'funding_total_usd', 'milestones', 'is_CA', 'is_NY', 'is_MA', 'is_TX', 'is_otherstate', 'is_software', 'is_web', 'is_mobile', 'is_enterprise', 'is_advertising', 'is_gamesvideo', 'is_ecommerce', 'is_biotech', 'is_consulting', 'is_othercategory', 'has_VC', 'has_angel', 'has_roundA', 'has_roundB', 'has_roundC', 'has_roundD', 'avg_participants']\n",
      "  ‚úÖ id normalizado\n",
      "  ‚úÖ age_first_funding_year normalizado\n",
      "  ‚úÖ age_last_funding_year normalizado\n",
      "  ‚úÖ age_first_milestone_year normalizado\n",
      "  ‚úÖ age_last_milestone_year normalizado\n",
      "  ‚úÖ relationships normalizado\n",
      "  ‚úÖ funding_rounds normalizado\n",
      "  ‚úÖ funding_total_usd normalizado\n",
      "  ‚úÖ milestones normalizado\n",
      "  ‚úÖ is_CA normalizado\n",
      "  ‚úÖ is_NY normalizado\n",
      "  ‚úÖ is_MA normalizado\n",
      "  ‚úÖ is_TX normalizado\n",
      "  ‚úÖ is_otherstate normalizado\n",
      "  ‚úÖ is_software normalizado\n",
      "  ‚úÖ is_web normalizado\n",
      "  ‚úÖ is_mobile normalizado\n",
      "  ‚úÖ is_enterprise normalizado\n",
      "  ‚úÖ is_advertising normalizado\n",
      "  ‚úÖ is_gamesvideo normalizado\n",
      "  ‚úÖ is_ecommerce normalizado\n",
      "  ‚úÖ is_biotech normalizado\n",
      "  ‚úÖ is_consulting normalizado\n",
      "  ‚úÖ is_othercategory normalizado\n",
      "  ‚úÖ has_VC normalizado\n",
      "  ‚úÖ has_angel normalizado\n",
      "  ‚úÖ has_roundA normalizado\n",
      "  ‚úÖ has_roundB normalizado\n",
      "  ‚úÖ has_roundC normalizado\n",
      "  ‚úÖ has_roundD normalizado\n",
      "  ‚úÖ avg_participants normalizado\n"
     ]
    }
   ],
   "source": [
    "# 6. Normaliza√ß√£o/Padroniza√ß√£o de vari√°veis num√©ricas\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "def normalizar_dados(train_df, test_df, numerical_columns, method='standard'):\n",
    "    \"\"\"Normaliza dados num√©ricos\"\"\"\n",
    "    train_norm = train_df.copy()\n",
    "    test_norm = test_df.copy()\n",
    "    \n",
    "    # Verificar quais colunas num√©ricas ainda existem ap√≥s processamento\n",
    "    existing_num_cols = [col for col in numerical_columns if col in train_norm.columns and col in test_norm.columns]\n",
    "    \n",
    "    print(f\"Colunas num√©ricas para normalizar: {existing_num_cols}\")\n",
    "    \n",
    "    if method == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        scaler = MinMaxScaler()\n",
    "    \n",
    "    for col in existing_num_cols:\n",
    "        if col in train_norm.columns and col in test_norm.columns:\n",
    "            # Normalizar cada coluna individualmente\n",
    "            scaler_col = StandardScaler() if method == 'standard' else MinMaxScaler()\n",
    "            train_norm[col] = scaler_col.fit_transform(train_norm[[col]]).ravel()\n",
    "            test_norm[col] = scaler_col.transform(test_norm[[col]]).ravel()\n",
    "            print(f\"  ‚úÖ {col} normalizado\")\n",
    "    \n",
    "    return train_norm, test_norm\n",
    "\n",
    "# Aplicar normaliza√ß√£o usando lista atualizada\n",
    "train_final, test_final = normalizar_dados(train_processed, test_processed, numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c6208050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICA√á√ÉO AP√ìS PROCESSAMENTO CATEG√ìRICO ===\n",
      "Train shape: (646, 33)\n",
      "Test shape: (277, 32)\n",
      "Colunas train: ['id', 'age_first_funding_year', 'age_last_funding_year', 'age_first_milestone_year', 'age_last_milestone_year', 'relationships', 'funding_rounds', 'funding_total_usd', 'milestones', 'is_CA', 'is_NY', 'is_MA', 'is_TX', 'is_otherstate', 'category_code', 'is_software', 'is_web', 'is_mobile', 'is_enterprise', 'is_advertising', 'is_gamesvideo', 'is_ecommerce', 'is_biotech', 'is_consulting', 'is_othercategory', 'has_VC', 'has_angel', 'has_roundA', 'has_roundB', 'has_roundC', 'has_roundD', 'avg_participants', 'labels']\n",
      "Colunas test: ['id', 'age_first_funding_year', 'age_last_funding_year', 'age_first_milestone_year', 'age_last_milestone_year', 'relationships', 'funding_rounds', 'funding_total_usd', 'milestones', 'is_CA', 'is_NY', 'is_MA', 'is_TX', 'is_otherstate', 'category_code', 'is_software', 'is_web', 'is_mobile', 'is_enterprise', 'is_advertising', 'is_gamesvideo', 'is_ecommerce', 'is_biotech', 'is_consulting', 'is_othercategory', 'has_VC', 'has_angel', 'has_roundA', 'has_roundB', 'has_roundC', 'has_roundD', 'avg_participants']\n"
     ]
    }
   ],
   "source": [
    "# Verificar estado dos dados ap√≥s processamento categ√≥rico\n",
    "print(\"=== VERIFICA√á√ÉO AP√ìS PROCESSAMENTO CATEG√ìRICO ===\")\n",
    "print(f\"Train shape: {train_processed.shape}\")\n",
    "print(f\"Test shape: {test_processed.shape}\")\n",
    "print(f\"Colunas train: {list(train_processed.columns)}\")\n",
    "print(f\"Colunas test: {list(test_processed.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fdccb5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICA√á√ÉO FINAL DOS DADOS PROCESSADOS ===\n",
      "üìè Train shape: (646, 33)\n",
      "üìè Test shape: (277, 32)\n",
      "üéØ Target identificado: labels\n",
      "üîÑ Colunas em comum: 32\n",
      "‚ùå S√≥ no train: set()\n",
      "‚ùå S√≥ no test: set()\n",
      "\n",
      "üîç Valores nulos train: 0\n",
      "üîç Valores nulos test: 0\n",
      "\n",
      "üìä Tipos de dados train:\n",
      "float64    31\n",
      "int32       1\n",
      "int64       1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ DADOS PRONTOS PARA MODELAGEM:\n",
      "   X_train: (646, 32)\n",
      "   y_train: (646,)\n",
      "   X_test: (277, 32)\n",
      "\n",
      "üéØ Distribui√ß√£o do target:\n",
      "labels\n",
      "1    418\n",
      "0    228\n",
      "Name: count, dtype: int64\n",
      "   Propor√ß√£o: labels\n",
      "1    0.647059\n",
      "0    0.352941\n",
      "Name: proportion, dtype: float64\n",
      "‚úÖ Classes razoavelmente balanceadas (ratio: 0.545)\n"
     ]
    }
   ],
   "source": [
    "# VERIFICA√á√ÉO FINAL COMPLETA\n",
    "print(\"=== VERIFICA√á√ÉO FINAL DOS DADOS PROCESSADOS ===\")\n",
    "\n",
    "# 1. Verificar shapes\n",
    "print(f\"üìè Train shape: {train_final.shape}\")\n",
    "print(f\"üìè Test shape: {test_final.shape}\")\n",
    "\n",
    "# 2. Verificar se as colunas s√£o iguais (exceto target)\n",
    "train_cols = set(train_final.columns)\n",
    "test_cols = set(test_final.columns)\n",
    "\n",
    "# Identificar poss√≠vel coluna target\n",
    "possible_targets = ['labels', 'target', 'success', 'y']\n",
    "target_col = None\n",
    "for col in possible_targets:\n",
    "    if col in train_cols and col not in test_cols:\n",
    "        target_col = col\n",
    "        break\n",
    "\n",
    "if target_col:\n",
    "    print(f\"üéØ Target identificado: {target_col}\")\n",
    "    train_cols.remove(target_col)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Target n√£o identificado claramente\")\n",
    "\n",
    "# 3. Verificar compatibilidade das colunas\n",
    "print(f\"üîÑ Colunas em comum: {len(train_cols & test_cols)}\")\n",
    "print(f\"‚ùå S√≥ no train: {train_cols - test_cols}\")\n",
    "print(f\"‚ùå S√≥ no test: {test_cols - train_cols}\")\n",
    "\n",
    "# 4. Verificar valores ausentes\n",
    "print(f\"\\nüîç Valores nulos train: {train_final.isnull().sum().sum()}\")\n",
    "print(f\"üîç Valores nulos test: {test_final.isnull().sum().sum()}\")\n",
    "\n",
    "# 5. Verificar tipos de dados\n",
    "print(f\"\\nüìä Tipos de dados train:\")\n",
    "print(train_final.dtypes.value_counts())\n",
    "\n",
    "# 6. Preparar dados para modelagem\n",
    "if target_col:\n",
    "    # Separar features e target\n",
    "    X_train = train_final.drop(target_col, axis=1)\n",
    "    y_train = train_final[target_col]\n",
    "    X_test = test_final.copy()\n",
    "    \n",
    "    print(f\"\\n‚úÖ DADOS PRONTOS PARA MODELAGEM:\")\n",
    "    print(f\"   X_train: {X_train.shape}\")\n",
    "    print(f\"   y_train: {y_train.shape}\")\n",
    "    print(f\"   X_test: {X_test.shape}\")\n",
    "    \n",
    "    # Verificar distribui√ß√£o do target\n",
    "    print(f\"\\nüéØ Distribui√ß√£o do target:\")\n",
    "    print(y_train.value_counts())\n",
    "    print(f\"   Propor√ß√£o: {y_train.value_counts(normalize=True)}\")\n",
    "    \n",
    "    # Verificar se h√° desbalanceamento\n",
    "    if len(y_train.value_counts()) == 2:\n",
    "        minority_class = y_train.value_counts().min()\n",
    "        majority_class = y_train.value_counts().max()\n",
    "        ratio = minority_class / majority_class\n",
    "        \n",
    "        if ratio < 0.3:\n",
    "            print(f\"‚ö†Ô∏è  ATEN√á√ÉO: Classes desbalanceadas (ratio: {ratio:.3f})\")\n",
    "            print(\"   Considere usar t√©cnicas de balanceamento ou m√©tricas adequadas\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Classes razoavelmente balanceadas (ratio: {ratio:.3f})\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå PROBLEMA: Target n√£o identificado - verifique os dados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7479d0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Divis√£o dos dados:\n",
      "   Treino: (516, 32)\n",
      "   Valida√ß√£o: (130, 32)\n",
      "\n",
      "üîß Treinando Random Forest...\n",
      "   CV AUC: 0.807 ¬± 0.056\n",
      "   Val AUC: 0.803\n",
      "\n",
      "üîß Treinando Gradient Boosting...\n",
      "   CV AUC: 0.776 ¬± 0.060\n",
      "   Val AUC: 0.824\n",
      "\n",
      "üîß Treinando Logistic Regression...\n",
      "   CV AUC: 0.763 ¬± 0.061\n",
      "   Val AUC: 0.770\n",
      "\n",
      "üèÜ Melhor modelo: Gradient Boosting\n",
      "   AUC: 0.824\n"
     ]
    }
   ],
   "source": [
    "# MODELAGEM - M√öLTIPLOS ALGORITMOS\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Dividir dados para valida√ß√£o\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"üìä Divis√£o dos dados:\")\n",
    "print(f\"   Treino: {X_train_split.shape}\")\n",
    "print(f\"   Valida√ß√£o: {X_val.shape}\")\n",
    "\n",
    "# 2. Testar m√∫ltiplos modelos\n",
    "modelos = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for nome, modelo in modelos.items():\n",
    "    print(f\"\\nüîß Treinando {nome}...\")\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(modelo, X_train_split, y_train_split, \n",
    "                               cv=5, scoring='roc_auc')\n",
    "    \n",
    "    # Treinar modelo completo\n",
    "    modelo.fit(X_train_split, y_train_split)\n",
    "    \n",
    "    # Predi√ß√µes\n",
    "    y_pred = modelo.predict(X_val)\n",
    "    y_pred_proba = modelo.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # M√©tricas\n",
    "    auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    resultados[nome] = {\n",
    "        'modelo': modelo,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'auc_val': auc\n",
    "    }\n",
    "    \n",
    "    print(f\"   CV AUC: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")\n",
    "    print(f\"   Val AUC: {auc:.3f}\")\n",
    "\n",
    "# 3. Escolher melhor modelo\n",
    "melhor_modelo = max(resultados.keys(), key=lambda x: resultados[x]['auc_val'])\n",
    "print(f\"\\nüèÜ Melhor modelo: {melhor_modelo}\")\n",
    "print(f\"   AUC: {resultados[melhor_modelo]['auc_val']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dca27c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Divis√£o dos dados:\n",
      "   Treino: (516, 32)\n",
      "   Valida√ß√£o: (130, 32)\n",
      "\n",
      "üîß Treinando Random Forest...\n",
      "   CV AUC: 0.807 ¬± 0.056\n",
      "   Val AUC: 0.803\n",
      "   Acur√°cia: 0.777\n",
      "   Precis√£o: 0.784\n",
      "   Recall: 0.905\n",
      "   F1-Score: 0.840\n",
      "\n",
      "üîß Treinando Gradient Boosting...\n",
      "   CV AUC: 0.776 ¬± 0.060\n",
      "   Val AUC: 0.824\n",
      "   Acur√°cia: 0.785\n",
      "   Precis√£o: 0.798\n",
      "   Recall: 0.893\n",
      "   F1-Score: 0.843\n",
      "\n",
      "üîß Treinando Logistic Regression...\n",
      "   CV AUC: 0.763 ¬± 0.061\n",
      "   Val AUC: 0.770\n",
      "   Acur√°cia: 0.708\n",
      "   Precis√£o: 0.761\n",
      "   Recall: 0.798\n",
      "   F1-Score: 0.779\n",
      "\n",
      "================================================================================\n",
      "üìä TABELA COMPARATIVA DE M√âTRICAS\n",
      "================================================================================\n",
      "             Modelo        CV AUC Val AUC Acur√°cia Precis√£o Recall F1-Score\n",
      "      Random Forest 0.807 ¬± 0.056   0.803    0.777    0.784  0.905    0.840\n",
      "  Gradient Boosting 0.776 ¬± 0.060   0.824    0.785    0.798  0.893    0.843\n",
      "Logistic Regression 0.763 ¬± 0.061   0.770    0.708    0.761  0.798    0.779\n",
      "\n",
      "üèÜ MELHOR MODELO: Gradient Boosting\n",
      "   AUC: 0.824\n",
      "   Acur√°cia: 0.785\n",
      "   F1-Score: 0.843\n",
      "\n",
      "üìã RELAT√ìRIO DETALHADO - Gradient Boosting\n",
      "==================================================\n",
      "\n",
      "üìà Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Fracasso       0.75      0.59      0.66        46\n",
      "     Sucesso       0.80      0.89      0.84        84\n",
      "\n",
      "    accuracy                           0.78       130\n",
      "   macro avg       0.77      0.74      0.75       130\n",
      "weighted avg       0.78      0.78      0.78       130\n",
      "\n",
      "\n",
      "üîç Matriz de Confus√£o:\n",
      "                  Predito\n",
      "              Fracasso  Sucesso\n",
      "Real Fracasso      27       19\n",
      "     Sucesso        9       75\n",
      "\n",
      "üìä Interpreta√ß√£o:\n",
      "   ‚úÖ Verdadeiros Negativos (Fracasso previsto corretamente): 27\n",
      "   ‚ùå Falsos Positivos (Fracasso previsto como Sucesso): 19\n",
      "   ‚ùå Falsos Negativos (Sucesso previsto como Fracasso): 9\n",
      "   ‚úÖ Verdadeiros Positivos (Sucesso previsto corretamente): 75\n",
      "\n",
      "üéØ TOP 10 FEATURES MAIS IMPORTANTES (Gradient Boosting):\n",
      "============================================================\n",
      " 1. relationships            : 0.2312\n",
      " 2. funding_total_usd        : 0.1581\n",
      " 3. age_last_milestone_year  : 0.1196\n",
      " 4. age_first_funding_year   : 0.1019\n",
      " 5. milestones               : 0.0823\n",
      " 6. id                       : 0.0665\n",
      " 7. avg_participants         : 0.0575\n",
      " 8. age_first_milestone_year : 0.0554\n",
      " 9. age_last_funding_year    : 0.0302\n",
      "10. category_code            : 0.0277\n"
     ]
    }
   ],
   "source": [
    "# MODELAGEM - M√öLTIPLOS ALGORITMOS COM M√âTRICAS COMPLETAS\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Dividir dados para valida√ß√£o\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"üìä Divis√£o dos dados:\")\n",
    "print(f\"   Treino: {X_train_split.shape}\")\n",
    "print(f\"   Valida√ß√£o: {X_val.shape}\")\n",
    "\n",
    "# 2. Testar m√∫ltiplos modelos\n",
    "modelos = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "resultados = {}\n",
    "metricas_comparacao = []\n",
    "\n",
    "for nome, modelo in modelos.items():\n",
    "    print(f\"\\nüîß Treinando {nome}...\")\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(modelo, X_train_split, y_train_split, \n",
    "                               cv=5, scoring='roc_auc')\n",
    "    \n",
    "    # Treinar modelo completo\n",
    "    modelo.fit(X_train_split, y_train_split)\n",
    "    \n",
    "    # Predi√ß√µes\n",
    "    y_pred = modelo.predict(X_val)\n",
    "    y_pred_proba = modelo.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Calcular todas as m√©tricas\n",
    "    auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    \n",
    "    # Armazenar resultados\n",
    "    resultados[nome] = {\n",
    "        'modelo': modelo,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'auc_val': auc,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    \n",
    "    # Para tabela comparativa\n",
    "    metricas_comparacao.append({\n",
    "        'Modelo': nome,\n",
    "        'CV AUC': f\"{cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\",\n",
    "        'Val AUC': f\"{auc:.3f}\",\n",
    "        'Acur√°cia': f\"{accuracy:.3f}\",\n",
    "        'Precis√£o': f\"{precision:.3f}\",\n",
    "        'Recall': f\"{recall:.3f}\",\n",
    "        'F1-Score': f\"{f1:.3f}\"\n",
    "    })\n",
    "    \n",
    "    print(f\"   CV AUC: {cv_scores.mean():.3f} ¬± {cv_scores.std():.3f}\")\n",
    "    print(f\"   Val AUC: {auc:.3f}\")\n",
    "    print(f\"   Acur√°cia: {accuracy:.3f}\")\n",
    "    print(f\"   Precis√£o: {precision:.3f}\")\n",
    "    print(f\"   Recall: {recall:.3f}\")\n",
    "    print(f\"   F1-Score: {f1:.3f}\")\n",
    "\n",
    "# 3. Tabela comparativa das m√©tricas\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä TABELA COMPARATIVA DE M√âTRICAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_metricas = pd.DataFrame(metricas_comparacao)\n",
    "print(df_metricas.to_string(index=False))\n",
    "\n",
    "# 4. Escolher melhor modelo (baseado em AUC)\n",
    "melhor_modelo_nome = max(resultados.keys(), key=lambda x: resultados[x]['auc_val'])\n",
    "melhor_resultado = resultados[melhor_modelo_nome]\n",
    "\n",
    "print(f\"\\nüèÜ MELHOR MODELO: {melhor_modelo_nome}\")\n",
    "print(f\"   AUC: {melhor_resultado['auc_val']:.3f}\")\n",
    "print(f\"   Acur√°cia: {melhor_resultado['accuracy']:.3f}\")\n",
    "print(f\"   F1-Score: {melhor_resultado['f1_score']:.3f}\")\n",
    "\n",
    "# 5. Relat√≥rio detalhado do melhor modelo\n",
    "print(f\"\\nüìã RELAT√ìRIO DETALHADO - {melhor_modelo_nome}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "melhor_modelo_obj = melhor_resultado['modelo']\n",
    "y_pred_melhor = melhor_modelo_obj.predict(X_val)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_val, y_pred_melhor, target_names=['Fracasso', 'Sucesso']))\n",
    "\n",
    "# Matriz de Confus√£o\n",
    "print(\"\\nüîç Matriz de Confus√£o:\")\n",
    "cm = confusion_matrix(y_val, y_pred_melhor)\n",
    "print(f\"                  Predito\")\n",
    "print(f\"              Fracasso  Sucesso\")\n",
    "print(f\"Real Fracasso     {cm[0,0]:3d}      {cm[0,1]:3d}\")\n",
    "print(f\"     Sucesso      {cm[1,0]:3d}      {cm[1,1]:3d}\")\n",
    "\n",
    "# Interpreta√ß√£o da matriz\n",
    "vn, fp, fn, vp = cm.ravel()\n",
    "print(f\"\\nüìä Interpreta√ß√£o:\")\n",
    "print(f\"   ‚úÖ Verdadeiros Negativos (Fracasso previsto corretamente): {vn}\")\n",
    "print(f\"   ‚ùå Falsos Positivos (Fracasso previsto como Sucesso): {fp}\")\n",
    "print(f\"   ‚ùå Falsos Negativos (Sucesso previsto como Fracasso): {fn}\")\n",
    "print(f\"   ‚úÖ Verdadeiros Positivos (Sucesso previsto corretamente): {vp}\")\n",
    "\n",
    "# 6. An√°lise de import√¢ncia das features (se for Random Forest ou Gradient Boosting)\n",
    "if melhor_modelo_nome in ['Random Forest', 'Gradient Boosting']:\n",
    "    print(f\"\\nüéØ TOP 10 FEATURES MAIS IMPORTANTES ({melhor_modelo_nome}):\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    importances = melhor_modelo_obj.feature_importances_\n",
    "    feature_names = X_train.columns\n",
    "    \n",
    "    # Criar DataFrame com import√¢ncias\n",
    "    df_importances = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importancia': importances\n",
    "    }).sort_values('Importancia', ascending=False)\n",
    "    \n",
    "    # Mostrar top 10\n",
    "    top_features = df_importances.head(10)\n",
    "    for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['Feature']:25s}: {row['Importancia']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8dcb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù GERANDO SUBMISS√ÉO COM GRADIENT BOOSTING\n",
      "=======================================================\n",
      "üèÜ Modelo escolhido: Gradient Boosting Original\n",
      "üìä AUC de valida√ß√£o: 0.8230\n",
      "\n",
      "Treinando modelo final em todos os dados...\n",
      "   X_train: (646, 32)\n",
      "   y_train: (646,)\n",
      "   X_test: (277, 32)\n",
      "‚úÖ Modelo treinado com sucesso!\n",
      "Gerando predi√ß√µes no test set...\n",
      "‚úÖ Predi√ß√µes geradas: 277 valores bin√°rios (0 ou 1)\n",
      "‚úÖ Usando coluna 'id' do dataset\n",
      "‚úÖ Arquivo 'submission_gradient_boosting.csv' salvo!\n",
      "\n",
      "üìã INFORMA√á√ïES DA SUBMISS√ÉO:\n",
      "   Linhas: 277\n",
      "   Colunas: ['id', 'labels']\n",
      "   Valores √∫nicos: [0, 1]\n",
      "\n",
      "Primeiras 10 linhas:\n",
      "    id  labels\n",
      "0   70       1\n",
      "1   23       0\n",
      "2  389       1\n",
      "3  872       1\n",
      "4  920       0\n",
      "5  690       1\n",
      "6  588       0\n",
      "7  144       0\n",
      "8  875       1\n",
      "9  900       1\n",
      "\n",
      "üìà ESTAT√çSTICAS DAS PREDI√á√ïES (0/1):\n",
      "   Total de predi√ß√µes: 277\n",
      "   Fracasso (0): 88 (31.8%)\n",
      "   Sucesso (1): 189 (68.2%)\n",
      "\n",
      "üìä ESTAT√çSTICAS DAS PROBABILIDADES (para an√°lise):\n",
      "   M√©dia das probabilidades: 0.6149\n",
      "   Mediana das probabilidades: 0.7283\n",
      "   Min: 0.0085\n",
      "   Max: 0.9856\n",
      "\n",
      "üìä DISTRIBUI√á√ÉO DAS PROBABILIDADES:\n",
      "   0.0-0.2:  46 startups ( 16.6%)\n",
      "   0.2-0.4:  27 startups (  9.7%)\n",
      "   0.4-0.6:  41 startups ( 14.8%)\n",
      "   0.6-0.8:  50 startups ( 18.1%)\n",
      "   0.8-1.0: 113 startups ( 40.8%)\n",
      "\n",
      "üîç COMPARA√á√ÉO COM TREINO:\n",
      "   Taxa de sucesso no treino: 64.7%\n",
      "   Taxa de sucesso predita no teste: 68.2%\n",
      "   Diferen√ßa: +3.5%\n",
      "‚úÖ Distribui√ß√µes similares - predi√ß√µes consistentes!\n",
      "\n",
      "üéØ AN√ÅLISE DO THRESHOLD:\n",
      "   Threshold padr√£o usado: 0.5\n",
      "   Probabilidades > 0.5: 189\n",
      "   Predi√ß√µes como sucesso (1): 189\n",
      "   ‚úÖ Consist√™ncia: OK\n",
      "\n",
      "üéâ SUBMISS√ÉO PRONTA!\n",
      "üìÅ Arquivo: submission_gradient_boosting.csv\n",
      "üèÜ Modelo: Gradient Boosting Original\n",
      "üìä AUC esperado: 0.8230\n",
      "üéØ Formato: Valores bin√°rios (0=Fracasso, 1=Sucesso)\n",
      "üí° Pronto para upload no Kaggle!\n"
     ]
    }
   ],
   "source": [
    "# SUBMISS√ÉO FINAL - GRADIENT BOOSTING ORIGINAL\n",
    "print(\"üìù GERANDO SUBMISS√ÉO COM GRADIENT BOOSTING\")\n",
    "print(\"=\"*55)\n",
    "\n",
    "# Usar o Gradient Boosting original (melhor modelo b√°sico)\n",
    "modelo_final = resultados['Gradient Boosting']['modelo']\n",
    "auc_final = resultados['Gradient Boosting']['auc_val']\n",
    "\n",
    "print(f\"üèÜ Modelo escolhido: Gradient Boosting Original\")\n",
    "print(f\"üìä AUC de valida√ß√£o: {auc_final:.4f}\")\n",
    "\n",
    "# Treinar modelo final em TODOS os dados de treino\n",
    "print(f\"\\nTreinando modelo final em todos os dados...\")\n",
    "print(f\"   X_train: {X_train.shape}\")\n",
    "print(f\"   y_train: {y_train.shape}\")\n",
    "print(f\"   X_test: {X_test.shape}\")\n",
    "\n",
    "modelo_final.fit(X_train, y_train)\n",
    "print(\"‚úÖ Modelo treinado com sucesso!\")\n",
    "\n",
    "# Fazer predi√ß√µes no test set\n",
    "print(\"Gerando predi√ß√µes no test set...\")\n",
    "# Predi√ß√µes bin√°rias (0 ou 1) - n√£o probabilidades\n",
    "predicoes_finais = modelo_final.predict(X_test)\n",
    "\n",
    "# Tamb√©m calcular probabilidades para an√°lise\n",
    "probabilidades = modelo_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"‚úÖ Predi√ß√µes geradas: {len(predicoes_finais)} valores bin√°rios (0 ou 1)\")\n",
    "\n",
    "# Verificar coluna ID\n",
    "if 'id' in test.columns:\n",
    "    id_col = test['id']\n",
    "    print(\"‚úÖ Usando coluna 'id' do dataset\")\n",
    "else:\n",
    "    id_col = range(len(test))\n",
    "    print(\"‚ö†Ô∏è Criando IDs sequenciais\")\n",
    "\n",
    "# Criar arquivo de submiss√£o com valores bin√°rios\n",
    "submission = pd.DataFrame({\n",
    "    'id': id_col,\n",
    "    'labels': predicoes_finais  # 0 ou 1\n",
    "})\n",
    "\n",
    "# Salvar submission\n",
    "nome_arquivo = 'submission_gradient_boosting.csv'\n",
    "submission.to_csv(nome_arquivo, index=False)\n",
    "print(f\"‚úÖ Arquivo '{nome_arquivo}' salvo!\")\n",
    "\n",
    "# Mostrar informa√ß√µes da submiss√£o\n",
    "print(f\"\\nüìã INFORMA√á√ïES DA SUBMISS√ÉO:\")\n",
    "print(f\"   Linhas: {len(submission)}\")\n",
    "print(f\"   Colunas: {list(submission.columns)}\")\n",
    "print(f\"   Valores √∫nicos: {sorted(submission['labels'].unique())}\")\n",
    "print(\"\\nPrimeiras 10 linhas:\")\n",
    "print(submission.head(10))\n",
    "\n",
    "# Estat√≠sticas das predi√ß√µes BIN√ÅRIAS\n",
    "print(f\"\\nüìà ESTAT√çSTICAS DAS PREDI√á√ïES (0/1):\")\n",
    "successo_predito = (predicoes_finais == 1).sum()\n",
    "fracasso_predito = (predicoes_finais == 0).sum()\n",
    "total = len(predicoes_finais)\n",
    "\n",
    "print(f\"   Total de predi√ß√µes: {total}\")\n",
    "print(f\"   Fracasso (0): {fracasso_predito} ({fracasso_predito/total*100:.1f}%)\")\n",
    "print(f\"   Sucesso (1): {successo_predito} ({successo_predito/total*100:.1f}%)\")\n",
    "\n",
    "# Estat√≠sticas das probabilidades (para an√°lise)\n",
    "print(f\"\\nüìä ESTAT√çSTICAS DAS PROBABILIDADES (para an√°lise):\")\n",
    "print(f\"   M√©dia das probabilidades: {probabilidades.mean():.4f}\")\n",
    "print(f\"   Mediana das probabilidades: {np.median(probabilidades):.4f}\")\n",
    "print(f\"   Min: {probabilidades.min():.4f}\")\n",
    "print(f\"   Max: {probabilidades.max():.4f}\")\n",
    "\n",
    "# Comparar com distribui√ß√£o do treino\n",
    "train_success_rate = y_train.mean()\n",
    "test_success_rate = successo_predito / total\n",
    "\n",
    "print(f\"\\nüîç COMPARA√á√ÉO COM TREINO:\")\n",
    "print(f\"   Taxa de sucesso no treino: {train_success_rate:.1%}\")\n",
    "print(f\"   Taxa de sucesso predita no teste: {test_success_rate:.1%}\")\n",
    "print(f\"   Diferen√ßa: {test_success_rate - train_success_rate:+.1%}\")\n",
    "\n",
    "if abs(test_success_rate - train_success_rate) < 0.1:\n",
    "    print(\"‚úÖ Distribui√ß√µes similares - predi√ß√µes consistentes!\")\n",
    "elif test_success_rate > train_success_rate + 0.1:\n",
    "    print(\"üìà Modelo prev√™ mais sucessos que o observado no treino\")\n",
    "else:\n",
    "    print(\"üìâ Modelo prev√™ menos sucessos que o observado no treino\")\n",
    "\n",
    "# Verificar threshold usado pelo modelo\n",
    "threshold_usado = 0.5\n",
    "acima_threshold = (probabilidades > threshold_usado).sum()\n",
    "print(f\"\\nüéØ AN√ÅLISE DO THRESHOLD:\")\n",
    "print(f\"   Threshold padr√£o usado: {threshold_usado}\")\n",
    "print(f\"   Probabilidades > {threshold_usado}: {acima_threshold}\")\n",
    "print(f\"   Predi√ß√µes como sucesso (1): {successo_predito}\")\n",
    "print(f\"   ‚úÖ Consist√™ncia: {'OK' if acima_threshold == successo_predito else 'ERRO'}\")\n",
    "\n",
    "print(f\"\\nüéâ SUBMISS√ÉO PRONTA!\")\n",
    "print(f\"üìÅ Arquivo: {nome_arquivo}\")\n",
    "print(f\"üèÜ Modelo: Gradient Boosting Original\")\n",
    "print(f\"üìä AUC esperado: {auc_final:.4f}\")\n",
    "print(f\"üéØ Formato: Valores bin√°rios (0=Fracasso, 1=Sucesso)\")\n",
    "print(f\"üí° Pronto para upload no Kaggle!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
