{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3948d6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (646, 33)\n",
      "Test: (277, 32)\n",
      "    id  age_first_funding_year  age_last_funding_year  \\\n",
      "0  719                   10.42                  13.09   \n",
      "1  429                    3.79                   3.79   \n",
      "2  178                    0.71                   2.28   \n",
      "3  197                    3.00                   5.00   \n",
      "4  444                    0.66                   5.88   \n",
      "\n",
      "   age_first_milestone_year  age_last_milestone_year  relationships  \\\n",
      "0                      8.98                    12.72              4   \n",
      "1                       NaN                      NaN             21   \n",
      "2                      1.95                     2.28              5   \n",
      "3                      9.62                    10.39             16   \n",
      "4                      6.21                     8.61             29   \n",
      "\n",
      "   funding_rounds  funding_total_usd  milestones  is_CA  ...  is_consulting  \\\n",
      "0               3            4087500           3      1  ...              0   \n",
      "1               1           45000000           0      0  ...              0   \n",
      "2               2            5200000           2      1  ...              0   \n",
      "3               2           14500000           2      0  ...              0   \n",
      "4               5           70000000           4      1  ...              0   \n",
      "\n",
      "   is_othercategory  has_VC  has_angel has_roundA  has_roundB  has_roundC  \\\n",
      "0                 0       1          1          0           0           0   \n",
      "1                 0       0          0          0           1           0   \n",
      "2                 1       1          0          1           0           0   \n",
      "3                 0       0          1          0           1           0   \n",
      "4                 0       0          0          1           1           1   \n",
      "\n",
      "   has_roundD  avg_participants  labels  \n",
      "0           0               1.0       0  \n",
      "1           0               1.0       1  \n",
      "2           0               1.0       0  \n",
      "3           0               2.0       1  \n",
      "4           1               2.8       1  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "                id  age_first_funding_year  age_last_funding_year  \\\n",
      "count   646.000000              611.000000             637.000000   \n",
      "unique         NaN                     NaN                    NaN   \n",
      "top            NaN                     NaN                    NaN   \n",
      "freq           NaN                     NaN                    NaN   \n",
      "mean    461.577399                2.341718               4.037724   \n",
      "std     264.859464                2.468275               2.950923   \n",
      "min       1.000000                0.000000               0.000000   \n",
      "25%     233.250000                0.680000               1.870000   \n",
      "50%     459.500000                1.650000               3.610000   \n",
      "75%     692.500000                3.600000               5.590000   \n",
      "max     923.000000               21.900000              21.900000   \n",
      "\n",
      "        age_first_milestone_year  age_last_milestone_year  relationships  \\\n",
      "count                 508.000000               535.000000     646.000000   \n",
      "unique                       NaN                      NaN            NaN   \n",
      "top                          NaN                      NaN            NaN   \n",
      "freq                         NaN                      NaN            NaN   \n",
      "mean                    3.352657                 4.944729       7.948916   \n",
      "std                     2.866952                 3.213319       7.397602   \n",
      "min                     0.000000                 0.000000       0.000000   \n",
      "25%                     1.185000                 2.540000       3.000000   \n",
      "50%                     2.785000                 4.620000       6.000000   \n",
      "75%                     4.935000                 6.880000      10.000000   \n",
      "max                    24.680000                24.680000      63.000000   \n",
      "\n",
      "        funding_rounds  funding_total_usd  milestones       is_CA  ...  \\\n",
      "count       646.000000       6.460000e+02  646.000000  646.000000  ...   \n",
      "unique             NaN                NaN         NaN         NaN  ...   \n",
      "top                NaN                NaN         NaN         NaN  ...   \n",
      "freq               NaN                NaN         NaN         NaN  ...   \n",
      "mean          2.351393       2.949633e+07    1.913313    0.546440  ...   \n",
      "std           1.357856       2.261999e+08    1.337095    0.498224  ...   \n",
      "min           1.000000       1.100000e+04    0.000000    0.000000  ...   \n",
      "25%           1.000000       3.000000e+06    1.000000    0.000000  ...   \n",
      "50%           2.000000       1.020000e+07    2.000000    1.000000  ...   \n",
      "75%           3.000000       2.587500e+07    3.000000    1.000000  ...   \n",
      "max           8.000000       5.700000e+09    6.000000    1.000000  ...   \n",
      "\n",
      "        is_consulting  is_othercategory      has_VC   has_angel  has_roundA  \\\n",
      "count      646.000000        646.000000  646.000000  646.000000  646.000000   \n",
      "unique            NaN               NaN         NaN         NaN         NaN   \n",
      "top               NaN               NaN         NaN         NaN         NaN   \n",
      "freq              NaN               NaN         NaN         NaN         NaN   \n",
      "mean         0.003096          0.304954    0.329721    0.260062    0.515480   \n",
      "std          0.055598          0.460745    0.470476    0.439008    0.500148   \n",
      "min          0.000000          0.000000    0.000000    0.000000    0.000000   \n",
      "25%          0.000000          0.000000    0.000000    0.000000    0.000000   \n",
      "50%          0.000000          0.000000    0.000000    0.000000    1.000000   \n",
      "75%          0.000000          1.000000    1.000000    1.000000    1.000000   \n",
      "max          1.000000          1.000000    1.000000    1.000000    1.000000   \n",
      "\n",
      "        has_roundB  has_roundC  has_roundD  avg_participants      labels  \n",
      "count   646.000000  646.000000  646.000000        646.000000  646.000000  \n",
      "unique         NaN         NaN         NaN               NaN         NaN  \n",
      "top            NaN         NaN         NaN               NaN         NaN  \n",
      "freq           NaN         NaN         NaN               NaN         NaN  \n",
      "mean      0.419505    0.235294    0.091331          2.848655    0.647059  \n",
      "std       0.493860    0.424511    0.288303          1.894050    0.478255  \n",
      "min       0.000000    0.000000    0.000000          1.000000    0.000000  \n",
      "25%       0.000000    0.000000    0.000000          1.500000    0.000000  \n",
      "50%       0.000000    0.000000    0.000000          2.333300    1.000000  \n",
      "75%       1.000000    0.000000    0.000000          4.000000    1.000000  \n",
      "max       1.000000    1.000000    1.000000         16.000000    1.000000  \n",
      "\n",
      "[11 rows x 33 columns]\n",
      "                id  age_first_funding_year  age_last_funding_year  \\\n",
      "count   277.000000              266.000000             273.000000   \n",
      "unique         NaN                     NaN                    NaN   \n",
      "top            NaN                     NaN                    NaN   \n",
      "freq           NaN                     NaN                    NaN   \n",
      "mean    462.985560                2.497857               3.924286   \n",
      "std     271.068618                2.446842               2.825445   \n",
      "min       4.000000                0.000000               0.000000   \n",
      "25%     215.000000                0.722500               1.760000   \n",
      "50%     464.000000                1.580000               3.510000   \n",
      "75%     692.000000                4.025000               5.560000   \n",
      "max     922.000000               16.420000              16.420000   \n",
      "\n",
      "        age_first_milestone_year  age_last_milestone_year  relationships  \\\n",
      "count                 217.000000               224.000000     277.000000   \n",
      "unique                       NaN                      NaN            NaN   \n",
      "top                          NaN                      NaN            NaN   \n",
      "freq                         NaN                      NaN            NaN   \n",
      "mean                    3.312535                 4.663348       7.155235   \n",
      "std                     2.553868                 2.847457       6.929857   \n",
      "min                     0.000000                 0.000000       0.000000   \n",
      "25%                     1.250000                 2.485000       3.000000   \n",
      "50%                     2.970000                 4.165000       5.000000   \n",
      "75%                     5.000000                 6.722500       9.000000   \n",
      "max                    13.010000                13.010000      57.000000   \n",
      "\n",
      "        funding_rounds  funding_total_usd  milestones       is_CA  ...  \\\n",
      "count       277.000000       2.770000e+02  277.000000  277.000000  ...   \n",
      "unique             NaN                NaN         NaN         NaN  ...   \n",
      "top                NaN                NaN         NaN         NaN  ...   \n",
      "freq               NaN                NaN         NaN         NaN  ...   \n",
      "mean          2.216606       1.591263e+07    1.675090    0.483755  ...   \n",
      "std           1.463324       2.068785e+07    1.275122    0.500641  ...   \n",
      "min           1.000000       2.000000e+04    0.000000    0.000000  ...   \n",
      "25%           1.000000       2.238055e+06    1.000000    0.000000  ...   \n",
      "50%           2.000000       9.000000e+06    1.000000    0.000000  ...   \n",
      "75%           3.000000       2.225000e+07    2.000000    1.000000  ...   \n",
      "max          10.000000       1.622641e+08    8.000000    1.000000  ...   \n",
      "\n",
      "        is_biotech  is_consulting  is_othercategory      has_VC   has_angel  \\\n",
      "count   277.000000     277.000000        277.000000  277.000000  277.000000   \n",
      "unique         NaN            NaN               NaN         NaN         NaN   \n",
      "top            NaN            NaN               NaN         NaN         NaN   \n",
      "freq           NaN            NaN               NaN         NaN         NaN   \n",
      "mean      0.032491       0.003610          0.364621    0.317690    0.241877   \n",
      "std       0.177621       0.060084          0.482195    0.466421    0.428995   \n",
      "min       0.000000       0.000000          0.000000    0.000000    0.000000   \n",
      "25%       0.000000       0.000000          0.000000    0.000000    0.000000   \n",
      "50%       0.000000       0.000000          0.000000    0.000000    0.000000   \n",
      "75%       0.000000       0.000000          1.000000    1.000000    0.000000   \n",
      "max       1.000000       1.000000          1.000000    1.000000    1.000000   \n",
      "\n",
      "        has_roundA  has_roundB  has_roundC  has_roundD  avg_participants  \n",
      "count   277.000000  277.000000  277.000000  277.000000        277.000000  \n",
      "unique         NaN         NaN         NaN         NaN               NaN  \n",
      "top            NaN         NaN         NaN         NaN               NaN  \n",
      "freq           NaN         NaN         NaN         NaN               NaN  \n",
      "mean      0.490975    0.328520    0.227437    0.119134          2.815103  \n",
      "std       0.500823    0.470525    0.419936    0.324532          1.831605  \n",
      "min       0.000000    0.000000    0.000000    0.000000          1.000000  \n",
      "25%       0.000000    0.000000    0.000000    0.000000          1.000000  \n",
      "50%       0.000000    0.000000    0.000000    0.000000          2.500000  \n",
      "75%       1.000000    1.000000    0.000000    0.000000          3.500000  \n",
      "max       1.000000    1.000000    1.000000    1.000000         11.000000  \n",
      "\n",
      "[11 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Carregar datasets\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Ver dimensões\n",
    "print(\"Train:\", train.shape)\n",
    "print(\"Test:\", test.shape)\n",
    "\n",
    "# Olhar primeiras linhas\n",
    "print(train.head())\n",
    "\n",
    "# Ver estatísticas gerais\n",
    "print(train.describe(include=\"all\"))\n",
    "print(test.describe(include=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c8c9c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INFORMAÇÕES GERAIS ===\n",
      "Train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 646 entries, 0 to 645\n",
      "Data columns (total 33 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   id                        646 non-null    int64  \n",
      " 1   age_first_funding_year    611 non-null    float64\n",
      " 2   age_last_funding_year     637 non-null    float64\n",
      " 3   age_first_milestone_year  508 non-null    float64\n",
      " 4   age_last_milestone_year   535 non-null    float64\n",
      " 5   relationships             646 non-null    int64  \n",
      " 6   funding_rounds            646 non-null    int64  \n",
      " 7   funding_total_usd         646 non-null    int64  \n",
      " 8   milestones                646 non-null    int64  \n",
      " 9   is_CA                     646 non-null    int64  \n",
      " 10  is_NY                     646 non-null    int64  \n",
      " 11  is_MA                     646 non-null    int64  \n",
      " 12  is_TX                     646 non-null    int64  \n",
      " 13  is_otherstate             646 non-null    int64  \n",
      " 14  category_code             646 non-null    object \n",
      " 15  is_software               646 non-null    int64  \n",
      " 16  is_web                    646 non-null    int64  \n",
      " 17  is_mobile                 646 non-null    int64  \n",
      " 18  is_enterprise             646 non-null    int64  \n",
      " 19  is_advertising            646 non-null    int64  \n",
      " 20  is_gamesvideo             646 non-null    int64  \n",
      " 21  is_ecommerce              646 non-null    int64  \n",
      " 22  is_biotech                646 non-null    int64  \n",
      " 23  is_consulting             646 non-null    int64  \n",
      " 24  is_othercategory          646 non-null    int64  \n",
      " 25  has_VC                    646 non-null    int64  \n",
      " 26  has_angel                 646 non-null    int64  \n",
      " 27  has_roundA                646 non-null    int64  \n",
      " 28  has_roundB                646 non-null    int64  \n",
      " 29  has_roundC                646 non-null    int64  \n",
      " 30  has_roundD                646 non-null    int64  \n",
      " 31  avg_participants          646 non-null    float64\n",
      " 32  labels                    646 non-null    int64  \n",
      "dtypes: float64(5), int64(27), object(1)\n",
      "memory usage: 166.7+ KB\n",
      "None\n",
      "\n",
      "Test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 277 entries, 0 to 276\n",
      "Data columns (total 32 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   id                        277 non-null    int64  \n",
      " 1   age_first_funding_year    266 non-null    float64\n",
      " 2   age_last_funding_year     273 non-null    float64\n",
      " 3   age_first_milestone_year  217 non-null    float64\n",
      " 4   age_last_milestone_year   224 non-null    float64\n",
      " 5   relationships             277 non-null    int64  \n",
      " 6   funding_rounds            277 non-null    int64  \n",
      " 7   funding_total_usd         277 non-null    int64  \n",
      " 8   milestones                277 non-null    int64  \n",
      " 9   is_CA                     277 non-null    int64  \n",
      " 10  is_NY                     277 non-null    int64  \n",
      " 11  is_MA                     277 non-null    int64  \n",
      " 12  is_TX                     277 non-null    int64  \n",
      " 13  is_otherstate             277 non-null    int64  \n",
      " 14  category_code             277 non-null    object \n",
      " 15  is_software               277 non-null    int64  \n",
      " 16  is_web                    277 non-null    int64  \n",
      " 17  is_mobile                 277 non-null    int64  \n",
      " 18  is_enterprise             277 non-null    int64  \n",
      " 19  is_advertising            277 non-null    int64  \n",
      " 20  is_gamesvideo             277 non-null    int64  \n",
      " 21  is_ecommerce              277 non-null    int64  \n",
      " 22  is_biotech                277 non-null    int64  \n",
      " 23  is_consulting             277 non-null    int64  \n",
      " 24  is_othercategory          277 non-null    int64  \n",
      " 25  has_VC                    277 non-null    int64  \n",
      " 26  has_angel                 277 non-null    int64  \n",
      " 27  has_roundA                277 non-null    int64  \n",
      " 28  has_roundB                277 non-null    int64  \n",
      " 29  has_roundC                277 non-null    int64  \n",
      " 30  has_roundD                277 non-null    int64  \n",
      " 31  avg_participants          277 non-null    float64\n",
      "dtypes: float64(5), int64(26), object(1)\n",
      "memory usage: 69.4+ KB\n",
      "None\n",
      "\n",
      "=== VALORES AUSENTES ===\n",
      "Train - valores nulos:\n",
      "id                            0\n",
      "age_first_funding_year       35\n",
      "age_last_funding_year         9\n",
      "age_first_milestone_year    138\n",
      "age_last_milestone_year     111\n",
      "relationships                 0\n",
      "funding_rounds                0\n",
      "funding_total_usd             0\n",
      "milestones                    0\n",
      "is_CA                         0\n",
      "is_NY                         0\n",
      "is_MA                         0\n",
      "is_TX                         0\n",
      "is_otherstate                 0\n",
      "category_code                 0\n",
      "is_software                   0\n",
      "is_web                        0\n",
      "is_mobile                     0\n",
      "is_enterprise                 0\n",
      "is_advertising                0\n",
      "is_gamesvideo                 0\n",
      "is_ecommerce                  0\n",
      "is_biotech                    0\n",
      "is_consulting                 0\n",
      "is_othercategory              0\n",
      "has_VC                        0\n",
      "has_angel                     0\n",
      "has_roundA                    0\n",
      "has_roundB                    0\n",
      "has_roundC                    0\n",
      "has_roundD                    0\n",
      "avg_participants              0\n",
      "labels                        0\n",
      "dtype: int64\n",
      "\n",
      "Test - valores nulos:\n",
      "id                           0\n",
      "age_first_funding_year      11\n",
      "age_last_funding_year        4\n",
      "age_first_milestone_year    60\n",
      "age_last_milestone_year     53\n",
      "relationships                0\n",
      "funding_rounds               0\n",
      "funding_total_usd            0\n",
      "milestones                   0\n",
      "is_CA                        0\n",
      "is_NY                        0\n",
      "is_MA                        0\n",
      "is_TX                        0\n",
      "is_otherstate                0\n",
      "category_code                0\n",
      "is_software                  0\n",
      "is_web                       0\n",
      "is_mobile                    0\n",
      "is_enterprise                0\n",
      "is_advertising               0\n",
      "is_gamesvideo                0\n",
      "is_ecommerce                 0\n",
      "is_biotech                   0\n",
      "is_consulting                0\n",
      "is_othercategory             0\n",
      "has_VC                       0\n",
      "has_angel                    0\n",
      "has_roundA                   0\n",
      "has_roundB                   0\n",
      "has_roundC                   0\n",
      "has_roundD                   0\n",
      "avg_participants             0\n",
      "dtype: int64\n",
      "\n",
      "=== DUPLICATAS ===\n",
      "Train duplicatas: 0\n",
      "Test duplicatas: 0\n"
     ]
    }
   ],
   "source": [
    "# ANÁLISE EXPLORATÓRIA INICIAL\n",
    "# Verificar informações gerais dos dados\n",
    "print(\"=== INFORMAÇÕES GERAIS ===\")\n",
    "print(\"Train info:\")\n",
    "print(train.info())\n",
    "print(\"\\nTest info:\")\n",
    "print(test.info())\n",
    "\n",
    "# Verificar valores ausentes\n",
    "print(\"\\n=== VALORES AUSENTES ===\")\n",
    "print(\"Train - valores nulos:\")\n",
    "print(train.isnull().sum())\n",
    "print(\"\\nTest - valores nulos:\")\n",
    "print(test.isnull().sum())\n",
    "\n",
    "# Verificar duplicatas\n",
    "print(\"\\n=== DUPLICATAS ===\")\n",
    "print(f\"Train duplicatas: {train.duplicated().sum()}\")\n",
    "print(f\"Test duplicatas: {test.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de444d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COLUNAS CATEGÓRICAS ===\n",
      "Index(['category_code'], dtype='object')\n",
      "\n",
      "=== COLUNAS NUMÉRICAS ===\n",
      "Index(['id', 'age_first_funding_year', 'age_last_funding_year',\n",
      "       'age_first_milestone_year', 'age_last_milestone_year', 'relationships',\n",
      "       'funding_rounds', 'funding_total_usd', 'milestones', 'is_CA', 'is_NY',\n",
      "       'is_MA', 'is_TX', 'is_otherstate', 'is_software', 'is_web', 'is_mobile',\n",
      "       'is_enterprise', 'is_advertising', 'is_gamesvideo', 'is_ecommerce',\n",
      "       'is_biotech', 'is_consulting', 'is_othercategory', 'has_VC',\n",
      "       'has_angel', 'has_roundA', 'has_roundB', 'has_roundC', 'has_roundD',\n",
      "       'avg_participants', 'labels'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "categorial_cols = train.select_dtypes(include=['object']).columns\n",
    "numerical_cols = train.select_dtypes(include=['number']).columns\n",
    "print(\"\\n=== COLUNAS CATEGÓRICAS ===\")\n",
    "print(categorial_cols) \n",
    "print(\"\\n=== COLUNAS NUMÉRICAS ===\")\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b44e9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "C:\\Users\\Inteli\\AppData\\Local\\Temp\\ipykernel_28256\\3086477320.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def tratar_valores_ausentes(df):\n",
    "    for col in df.columns:\n",
    "        if col in categorial_cols:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "    return df\n",
    "\n",
    "train = tratar_valores_ausentes(train)\n",
    "test = tratar_valores_ausentes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1502946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna id - Outliers: 0\n",
      "Coluna age_first_funding_year - Outliers: 20\n",
      "Coluna age_last_funding_year - Outliers: 11\n",
      "Coluna age_first_milestone_year - Outliers: 41\n",
      "Coluna age_last_milestone_year - Outliers: 22\n",
      "Coluna relationships - Outliers: 47\n",
      "Coluna funding_rounds - Outliers: 10\n",
      "Coluna funding_total_usd - Outliers: 50\n",
      "Coluna milestones - Outliers: 0\n",
      "Coluna is_CA - Outliers: 0\n",
      "Coluna is_NY - Outliers: 71\n",
      "Coluna is_MA - Outliers: 61\n",
      "Coluna is_TX - Outliers: 24\n",
      "Coluna is_otherstate - Outliers: 136\n",
      "Coluna is_software - Outliers: 105\n",
      "Coluna is_web - Outliers: 97\n",
      "Coluna is_mobile - Outliers: 65\n",
      "Coluna is_enterprise - Outliers: 53\n",
      "Coluna is_advertising - Outliers: 45\n",
      "Coluna is_gamesvideo - Outliers: 37\n",
      "Coluna is_ecommerce - Outliers: 20\n",
      "Coluna is_biotech - Outliers: 25\n",
      "Coluna is_consulting - Outliers: 2\n",
      "Coluna is_othercategory - Outliers: 0\n",
      "Coluna has_VC - Outliers: 0\n",
      "Coluna has_angel - Outliers: 0\n",
      "Coluna has_roundA - Outliers: 0\n",
      "Coluna has_roundB - Outliers: 0\n",
      "Coluna has_roundC - Outliers: 152\n",
      "Coluna has_roundD - Outliers: 59\n",
      "Coluna avg_participants - Outliers: 19\n",
      "Coluna labels - Outliers: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Tratamento de outliers (truncamento)\\ndef tratar_outliers_truncamento(df):\\n    for col in numerical_cols:\\n        Q1 = df[col].quantile(0.25)\\n        Q3 = df[col].quantile(0.75)\\n        IQR = Q3 - Q1\\n        lower_bound = Q1 - 1.5 * IQR\\n        upper_bound = Q3 + 1.5 * IQR\\n        df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\\n        df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\\n    return df\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def identificar_outliers_iqr(df):\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    return outliers\n",
    "\n",
    "for col in numerical_cols:\n",
    "    outliers = identificar_outliers_iqr(train)\n",
    "    print(f\"Coluna {col} - Outliers: {len(outliers)}\")\n",
    "\n",
    "'''\n",
    "# Tratamento de outliers (truncamento)\n",
    "def tratar_outliers_truncamento(df):\n",
    "    for col in numerical_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "        df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "    return df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a76c6405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colunas categóricas\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def processar_colunas_categoricas(df):\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    df_encoded = pd.DataFrame(encoder.fit_transform(df[categorial_cols]))\n",
    "    df_encoded.columns = encoder.get_feature_names_out(categorial_cols)\n",
    "    df = df.drop(categorial_cols, axis=1)\n",
    "    df = pd.concat([df, df_encoded], axis=1)\n",
    "    return df\n",
    "\n",
    "train_encoded = processar_colunas_categoricas(train)\n",
    "test_encoded = processar_colunas_categoricas(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c69365a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Pulando coluna de ID: id\n",
      "⚠️ Pulando coluna binária: is_CA\n",
      "⚠️ Pulando coluna binária: is_NY\n",
      "⚠️ Pulando coluna binária: is_MA\n",
      "⚠️ Pulando coluna binária: is_TX\n",
      "⚠️ Pulando coluna binária: is_otherstate\n",
      "⚠️ Pulando coluna binária: is_software\n",
      "⚠️ Pulando coluna binária: is_web\n",
      "⚠️ Pulando coluna binária: is_mobile\n",
      "⚠️ Pulando coluna binária: is_enterprise\n",
      "⚠️ Pulando coluna binária: is_advertising\n",
      "⚠️ Pulando coluna de ID: is_gamesvideo\n",
      "⚠️ Pulando coluna binária: is_ecommerce\n",
      "⚠️ Pulando coluna binária: is_biotech\n",
      "⚠️ Pulando coluna binária: is_consulting\n",
      "⚠️ Pulando coluna binária: is_othercategory\n",
      "⚠️ Pulando coluna binária: has_VC\n",
      "⚠️ Pulando coluna binária: has_angel\n",
      "⚠️ Pulando coluna binária: has_roundA\n",
      "⚠️ Pulando coluna binária: has_roundB\n",
      "⚠️ Pulando coluna binária: has_roundC\n",
      "⚠️ Pulando coluna binária: has_roundD\n",
      "⚠️ Pulando coluna binária: category_code_advertising\n",
      "⚠️ Pulando coluna binária: category_code_analytics\n",
      "⚠️ Pulando coluna binária: category_code_automotive\n",
      "⚠️ Pulando coluna binária: category_code_biotech\n",
      "⚠️ Pulando coluna binária: category_code_cleantech\n",
      "⚠️ Pulando coluna binária: category_code_consulting\n",
      "⚠️ Pulando coluna binária: category_code_ecommerce\n",
      "⚠️ Pulando coluna binária: category_code_education\n",
      "⚠️ Pulando coluna binária: category_code_enterprise\n",
      "⚠️ Pulando coluna binária: category_code_fashion\n",
      "⚠️ Pulando coluna binária: category_code_finance\n",
      "⚠️ Pulando coluna de ID: category_code_games_video\n",
      "⚠️ Pulando coluna binária: category_code_hardware\n",
      "⚠️ Pulando coluna binária: category_code_health\n",
      "⚠️ Pulando coluna binária: category_code_manufacturing\n",
      "⚠️ Pulando coluna binária: category_code_medical\n",
      "⚠️ Pulando coluna binária: category_code_messaging\n",
      "⚠️ Pulando coluna binária: category_code_mobile\n",
      "⚠️ Pulando coluna binária: category_code_music\n",
      "⚠️ Pulando coluna binária: category_code_network_hosting\n",
      "⚠️ Pulando coluna binária: category_code_news\n",
      "⚠️ Pulando coluna binária: category_code_other\n",
      "⚠️ Pulando coluna de ID: category_code_photo_video\n",
      "⚠️ Pulando coluna binária: category_code_public_relations\n",
      "⚠️ Pulando coluna binária: category_code_real_estate\n",
      "⚠️ Pulando coluna binária: category_code_search\n",
      "⚠️ Pulando coluna binária: category_code_security\n",
      "⚠️ Pulando coluna binária: category_code_semiconductor\n",
      "⚠️ Pulando coluna binária: category_code_social\n",
      "⚠️ Pulando coluna binária: category_code_software\n",
      "⚠️ Pulando coluna binária: category_code_sports\n",
      "⚠️ Pulando coluna binária: category_code_transportation\n",
      "⚠️ Pulando coluna binária: category_code_travel\n",
      "⚠️ Pulando coluna binária: category_code_web\n",
      "✅ Normalizadas 9 colunas:\n",
      "   - age_first_funding_year\n",
      "   - age_last_funding_year\n",
      "   - age_first_milestone_year\n",
      "   - age_last_milestone_year\n",
      "   - relationships\n",
      "   - funding_rounds\n",
      "   - funding_total_usd\n",
      "   - milestones\n",
      "   - avg_participants\n",
      "⚠️ Pulando coluna de ID: id\n",
      "⚠️ Pulando coluna binária: is_CA\n",
      "⚠️ Pulando coluna binária: is_NY\n",
      "⚠️ Pulando coluna binária: is_MA\n",
      "⚠️ Pulando coluna binária: is_TX\n",
      "⚠️ Pulando coluna binária: is_otherstate\n",
      "⚠️ Pulando coluna binária: is_software\n",
      "⚠️ Pulando coluna binária: is_web\n",
      "⚠️ Pulando coluna binária: is_mobile\n",
      "⚠️ Pulando coluna binária: is_enterprise\n",
      "⚠️ Pulando coluna binária: is_advertising\n",
      "⚠️ Pulando coluna de ID: is_gamesvideo\n",
      "⚠️ Pulando coluna binária: is_ecommerce\n",
      "⚠️ Pulando coluna binária: is_biotech\n",
      "⚠️ Pulando coluna binária: is_consulting\n",
      "⚠️ Pulando coluna binária: is_othercategory\n",
      "⚠️ Pulando coluna binária: has_VC\n",
      "⚠️ Pulando coluna binária: has_angel\n",
      "⚠️ Pulando coluna binária: has_roundA\n",
      "⚠️ Pulando coluna binária: has_roundB\n",
      "⚠️ Pulando coluna binária: has_roundC\n",
      "⚠️ Pulando coluna binária: has_roundD\n",
      "⚠️ Pulando coluna binária: category_code_advertising\n",
      "⚠️ Pulando coluna binária: category_code_analytics\n",
      "⚠️ Pulando coluna binária: category_code_automotive\n",
      "⚠️ Pulando coluna binária: category_code_biotech\n",
      "⚠️ Pulando coluna binária: category_code_cleantech\n",
      "⚠️ Pulando coluna binária: category_code_consulting\n",
      "⚠️ Pulando coluna binária: category_code_ecommerce\n",
      "⚠️ Pulando coluna binária: category_code_education\n",
      "⚠️ Pulando coluna binária: category_code_enterprise\n",
      "⚠️ Pulando coluna binária: category_code_fashion\n",
      "⚠️ Pulando coluna binária: category_code_finance\n",
      "⚠️ Pulando coluna de ID: category_code_games_video\n",
      "⚠️ Pulando coluna binária: category_code_hardware\n",
      "⚠️ Pulando coluna binária: category_code_health\n",
      "⚠️ Pulando coluna binária: category_code_hospitality\n",
      "⚠️ Pulando coluna binária: category_code_manufacturing\n",
      "⚠️ Pulando coluna binária: category_code_medical\n",
      "⚠️ Pulando coluna binária: category_code_messaging\n",
      "⚠️ Pulando coluna binária: category_code_mobile\n",
      "⚠️ Pulando coluna binária: category_code_music\n",
      "⚠️ Pulando coluna binária: category_code_network_hosting\n",
      "⚠️ Pulando coluna binária: category_code_news\n",
      "⚠️ Pulando coluna binária: category_code_other\n",
      "⚠️ Pulando coluna de ID: category_code_photo_video\n",
      "⚠️ Pulando coluna binária: category_code_public_relations\n",
      "⚠️ Pulando coluna binária: category_code_real_estate\n",
      "⚠️ Pulando coluna binária: category_code_search\n",
      "⚠️ Pulando coluna binária: category_code_security\n",
      "⚠️ Pulando coluna binária: category_code_semiconductor\n",
      "⚠️ Pulando coluna binária: category_code_social\n",
      "⚠️ Pulando coluna binária: category_code_software\n",
      "⚠️ Pulando coluna binária: category_code_travel\n",
      "⚠️ Pulando coluna binária: category_code_web\n",
      "✅ Normalizadas 9 colunas:\n",
      "   - age_first_funding_year\n",
      "   - age_last_funding_year\n",
      "   - age_first_milestone_year\n",
      "   - age_last_milestone_year\n",
      "   - relationships\n",
      "   - funding_rounds\n",
      "   - funding_total_usd\n",
      "   - milestones\n",
      "   - avg_participants\n",
      "\n",
      "📊 Shapes após normalização:\n",
      "   Train: (646, 66)\n",
      "   Test: (277, 64)\n",
      "\n",
      "📋 Tipos de dados após normalização:\n",
      "Train:\n",
      "float64    43\n",
      "int64      23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test:\n",
      "float64    42\n",
      "int64      22\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Normalização das colunas numéricas - VERSÃO MELHORADA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def normalizar_colunas_numericas(df, excluir_colunas=None):\n",
    "    \"\"\"Normaliza todas as colunas numéricas exceto binárias e de ID\"\"\"\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    if excluir_colunas is None:\n",
    "        excluir_colunas = []\n",
    "    \n",
    "    # Identificar colunas para normalizar\n",
    "    colunas_para_normalizar = []\n",
    "    \n",
    "    for col in df_normalized.columns:\n",
    "        # Pular se estiver na lista de exclusão\n",
    "        if col in excluir_colunas:\n",
    "            continue\n",
    "            \n",
    "        # Pular colunas de ID (que contenham 'id' no nome)\n",
    "        if 'id' in col.lower():\n",
    "            print(f\"⚠️ Pulando coluna de ID: {col}\")\n",
    "            continue\n",
    "            \n",
    "        # Verificar se é coluna numérica\n",
    "        if df_normalized[col].dtype in ['int64', 'float64', 'int32', 'float32']:\n",
    "            # Verificar se é coluna binária (só tem valores 0 e 1)\n",
    "            valores_unicos = df_normalized[col].dropna().unique()\n",
    "            \n",
    "            # Se só tem 2 valores únicos e são 0 e 1, é binária\n",
    "            if len(valores_unicos) == 2 and set(valores_unicos) == {0, 1}:\n",
    "                print(f\"⚠️ Pulando coluna binária: {col}\")\n",
    "                continue\n",
    "            \n",
    "            # Se só tem 2 valores únicos mas não são 0 e 1, ainda pode ser categórica\n",
    "            elif len(valores_unicos) == 2:\n",
    "                print(f\"⚠️ Pulando coluna com 2 valores únicos: {col} (valores: {valores_unicos})\")\n",
    "                continue\n",
    "                \n",
    "            # Se tem mais variação, normalizar\n",
    "            else:\n",
    "                colunas_para_normalizar.append(col)\n",
    "    \n",
    "    # Aplicar normalização\n",
    "    if colunas_para_normalizar:\n",
    "        scaler = StandardScaler()\n",
    "        df_normalized[colunas_para_normalizar] = scaler.fit_transform(df_normalized[colunas_para_normalizar])\n",
    "        print(f\"✅ Normalizadas {len(colunas_para_normalizar)} colunas:\")\n",
    "        for col in colunas_para_normalizar:\n",
    "            print(f\"   - {col}\")\n",
    "    else:\n",
    "        print(\"⚠️ Nenhuma coluna encontrada para normalizar\")\n",
    "    \n",
    "    return df_normalized\n",
    "\n",
    "# Aplicar normalização\n",
    "# Para train: excluir a coluna target 'labels'\n",
    "train_features = train_encoded.drop('labels', axis=1, errors='ignore')\n",
    "train_normalized = normalizar_colunas_numericas(train_features, excluir_colunas=['labels'])\n",
    "\n",
    "# Para test: sem exclusões específicas (não tem labels)\n",
    "test_normalized = normalizar_colunas_numericas(test_encoded)\n",
    "\n",
    "# Adicionar de volta a coluna 'labels' ao train\n",
    "if 'labels' in train_encoded.columns:\n",
    "    train_normalized['labels'] = train_encoded['labels']\n",
    "\n",
    "print(f\"\\n📊 Shapes após normalização:\")\n",
    "print(f\"   Train: {train_normalized.shape}\")\n",
    "print(f\"   Test: {test_normalized.shape}\")\n",
    "\n",
    "# Verificar tipos de dados finais\n",
    "print(f\"\\n📋 Tipos de dados após normalização:\")\n",
    "print(\"Train:\")\n",
    "print(train_normalized.dtypes.value_counts())\n",
    "print(\"\\nTest:\")\n",
    "print(test_normalized.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b386a8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Treinando modelo: Random Forest ===\n",
      "Cross-validation ROC AUC scores: [0.75820975 0.85619703 0.86179957 0.76158405 0.68561422]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.59      0.66        68\n",
      "           1       0.80      0.89      0.84       126\n",
      "\n",
      "    accuracy                           0.78       194\n",
      "   macro avg       0.77      0.74      0.75       194\n",
      "weighted avg       0.78      0.78      0.78       194\n",
      "\n",
      "ROC AUC: 0.8265056022408963\n",
      "\n",
      "=== Treinando modelo: Gradient Boosting ===\n",
      "Cross-validation ROC AUC scores: [0.75158898 0.82944915 0.82273707 0.75538793 0.6799569 ]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.57      0.65        68\n",
      "           1       0.80      0.90      0.84       126\n",
      "\n",
      "    accuracy                           0.78       194\n",
      "   macro avg       0.77      0.74      0.75       194\n",
      "weighted avg       0.78      0.78      0.78       194\n",
      "\n",
      "ROC AUC: 0.830532212885154\n",
      "\n",
      "=== Treinando modelo: Logistic Regression ===\n",
      "Cross-validation ROC AUC scores: [0.6996822  0.8220339  0.79579741 0.70150862 0.67510776]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.64        68\n",
      "           1       0.80      0.84      0.82       126\n",
      "\n",
      "    accuracy                           0.76       194\n",
      "   macro avg       0.73      0.72      0.73       194\n",
      "weighted avg       0.75      0.76      0.75       194\n",
      "\n",
      "ROC AUC: 0.8049719887955182\n"
     ]
    }
   ],
   "source": [
    "# MODELAGEM - MÚLTIPLOS ALGORITMOS\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "target_col = 'labels'\n",
    "train_final = train_normalized.copy()\n",
    "test_final = test_normalized.copy()\n",
    "\n",
    "X_train = train_final.drop(target_col, axis=1)\n",
    "y_train = train_final[target_col]\n",
    "X_test = test_final.copy()\n",
    "\n",
    "# 1. Dividir dados para validação\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "modelos = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "for nome, modelo in modelos.items():\n",
    "    print(f\"\\n=== Treinando modelo: {nome} ===\")\n",
    "\n",
    "    cv_scores = cross_val_score(modelo, X_train_split, y_train_split, cv=5, scoring='roc_auc')\n",
    "    print(f\"Cross-validation ROC AUC scores: {cv_scores}\")\n",
    "\n",
    "    #Treinar modelo\n",
    "    modelo.fit(X_train_split, y_train_split)\n",
    "\n",
    "    #Prever no conjunto de validação\n",
    "    y_pred = modelo.predict(X_val)\n",
    "\n",
    "    #Métricas para avaliar modelo\n",
    "    resultados[nome] = {\n",
    "        'modelo': modelo,\n",
    "        'report': classification_report(y_val, y_pred, output_dict=True),\n",
    "        'confusion_matrix': confusion_matrix(y_val, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_val, modelo.predict_proba(X_val)[:, 1])\n",
    "    }\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(f\"ROC AUC: {resultados[nome]['roc_auc']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25639a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 OTIMIZAÇÃO DE HIPERPARÂMETROS\n",
      "==================================================\n",
      "\n",
      "🔧 Tuning Gradient Boosting...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "✅ Melhores parâmetros GB: {'subsample': 0.9, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 4, 'learning_rate': 0.05}\n",
      "✅ Melhor score CV: 0.7936\n",
      "\n",
      "🔧 Tuning Random Forest...\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "✅ Melhores parâmetros RF: {'n_estimators': 300, 'min_samples_split': 20, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20, 'class_weight': None, 'bootstrap': True}\n",
      "✅ Melhor score CV: 0.7960\n"
     ]
    }
   ],
   "source": [
    "# OTIMIZAÇÃO DE HIPERPARÂMETROS\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"🚀 OTIMIZAÇÃO DE HIPERPARÂMETROS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. TUNING GRADIENT BOOSTING (melhor modelo atual)\n",
    "print(\"\\n🔧 Tuning Gradient Boosting...\")\n",
    "\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 6],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV é mais rápido que GridSearchCV\n",
    "gb_random = RandomizedSearchCV(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    param_distributions=gb_params,\n",
    "    n_iter=100,  # Número de combinações a testar\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gb_random.fit(X_train_split, y_train_split)\n",
    "\n",
    "print(f\"✅ Melhores parâmetros GB: {gb_random.best_params_}\")\n",
    "print(f\"✅ Melhor score CV: {gb_random.best_score_:.4f}\")\n",
    "\n",
    "# 2. TUNING RANDOM FOREST\n",
    "print(\"\\n🔧 Tuning Random Forest...\")\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "    'max_features': ['sqrt', 'log2', None, 0.8],\n",
    "    'bootstrap': [True, False],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_distributions=rf_params,\n",
    "    n_iter=80,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_random.fit(X_train_split, y_train_split)\n",
    "\n",
    "print(f\"✅ Melhores parâmetros RF: {rf_random.best_params_}\")\n",
    "print(f\"✅ Melhor score CV: {rf_random.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dba65a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🛠️ FEATURE ENGINEERING AVANÇADO\n",
      "========================================\n",
      "Criando features de interação...\n",
      "Criando features temporais...\n",
      "Criando features de localização...\n",
      "Criando features de categoria...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['category_code_sports', 'category_code_transportation'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 119\u001b[39m\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_fe, test_fe\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# Aplicar feature engineering\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m X_train_fe, X_test_fe = \u001b[43mcriar_features_avancadas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Garantir mesmas colunas\u001b[39;00m\n\u001b[32m    122\u001b[39m common_cols = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(X_train_fe.columns) & \u001b[38;5;28mset\u001b[39m(X_test_fe.columns))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mcriar_features_avancadas\u001b[39m\u001b[34m(df_train, df_test)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m category_cols:\n\u001b[32m     64\u001b[39m     train_fe[\u001b[33m'\u001b[39m\u001b[33mtotal_categories\u001b[39m\u001b[33m'\u001b[39m] = train_fe[category_cols].sum(axis=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     test_fe[\u001b[33m'\u001b[39m\u001b[33mtotal_categories\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mtest_fe\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategory_cols\u001b[49m\u001b[43m]\u001b[49m.sum(axis=\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# Features de tipo de funding\u001b[39;00m\n\u001b[32m     68\u001b[39m funding_type_cols = [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m train_fe.columns \u001b[38;5;28;01mif\u001b[39;00m col.startswith(\u001b[33m'\u001b[39m\u001b[33mhas_\u001b[39m\u001b[33m'\u001b[39m)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['category_code_sports', 'category_code_transportation'] not in index\""
     ]
    }
   ],
   "source": [
    "# FEATURE ENGINEERING AVANÇADO\n",
    "print(\"\\n🛠️ FEATURE ENGINEERING AVANÇADO\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "def criar_features_avancadas(df_train, df_test):\n",
    "    \"\"\"Cria features derivadas baseadas nas mais importantes\"\"\"\n",
    "    \n",
    "    # Copiar dataframes\n",
    "    train_fe = df_train.copy()\n",
    "    test_fe = df_test.copy()\n",
    "    \n",
    "    # 1. FEATURES DE INTERAÇÃO (baseadas na análise de importância)\n",
    "    print(\"Criando features de interação...\")\n",
    "    \n",
    "    # Relationships por funding round\n",
    "    if 'relationships' in train_fe.columns and 'funding_rounds' in train_fe.columns:\n",
    "        train_fe['relationships_per_round'] = train_fe['relationships'] / (train_fe['funding_rounds'] + 1)\n",
    "        test_fe['relationships_per_round'] = test_fe['relationships'] / (test_fe['funding_rounds'] + 1)\n",
    "    \n",
    "    # Funding total por round\n",
    "    if 'funding_total_usd' in train_fe.columns and 'funding_rounds' in train_fe.columns:\n",
    "        train_fe['funding_per_round'] = train_fe['funding_total_usd'] / (train_fe['funding_rounds'] + 1)\n",
    "        test_fe['funding_per_round'] = test_fe['funding_total_usd'] / (test_fe['funding_rounds'] + 1)\n",
    "    \n",
    "    # Milestones por relationship\n",
    "    if 'milestones' in train_fe.columns and 'relationships' in train_fe.columns:\n",
    "        train_fe['milestones_per_relationship'] = train_fe['milestones'] / (train_fe['relationships'] + 1)\n",
    "        test_fe['milestones_per_relationship'] = test_fe['milestones'] / (test_fe['relationships'] + 1)\n",
    "    \n",
    "    # 2. FEATURES TEMPORAIS\n",
    "    print(\"Criando features temporais...\")\n",
    "    \n",
    "    # Duração entre primeiro e último funding\n",
    "    age_cols = [col for col in train_fe.columns if 'age_' in col and 'funding' in col]\n",
    "    if len(age_cols) >= 2:\n",
    "        first_funding = [col for col in age_cols if 'first' in col][0]\n",
    "        last_funding = [col for col in age_cols if 'last' in col][0]\n",
    "        \n",
    "        train_fe['funding_duration'] = train_fe[last_funding] - train_fe[first_funding]\n",
    "        test_fe['funding_duration'] = test_fe[last_funding] - test_fe[first_funding]\n",
    "    \n",
    "    # Duração entre primeiro e último milestone\n",
    "    milestone_cols = [col for col in train_fe.columns if 'age_' in col and 'milestone' in col]\n",
    "    if len(milestone_cols) >= 2:\n",
    "        first_milestone = [col for col in milestone_cols if 'first' in col][0]\n",
    "        last_milestone = [col for col in milestone_cols if 'last' in col][0]\n",
    "        \n",
    "        train_fe['milestone_duration'] = train_fe[last_milestone] - train_fe[first_milestone]\n",
    "        test_fe['milestone_duration'] = test_fe[last_milestone] - test_fe[first_milestone]\n",
    "    \n",
    "    # 3. FEATURES DE LOCALIZAÇÃO AGREGADAS\n",
    "    print(\"Criando features de localização...\")\n",
    "    \n",
    "    location_cols = [col for col in train_fe.columns if col.startswith('is_') and any(state in col for state in ['CA', 'NY', 'MA', 'TX'])]\n",
    "    if location_cols:\n",
    "        train_fe['is_major_state'] = train_fe[location_cols].sum(axis=1).clip(0, 1)\n",
    "        test_fe['is_major_state'] = test_fe[location_cols].sum(axis=1).clip(0, 1)\n",
    "    \n",
    "    # 4. FEATURES DE CATEGORIA AGREGADAS\n",
    "    print(\"Criando features de categoria...\")\n",
    "    \n",
    "    category_cols = [col for col in train_fe.columns if col.startswith('category_code_')]\n",
    "    if category_cols:\n",
    "        train_fe['total_categories'] = train_fe[category_cols].sum(axis=1)\n",
    "        test_fe['total_categories'] = test_fe[category_cols].sum(axis=1)\n",
    "    \n",
    "    # Features de tipo de funding\n",
    "    funding_type_cols = [col for col in train_fe.columns if col.startswith('has_')]\n",
    "    if funding_type_cols:\n",
    "        train_fe['total_funding_types'] = train_fe[funding_type_cols].sum(axis=1)\n",
    "        test_fe['total_funding_types'] = test_fe[funding_type_cols].sum(axis=1)\n",
    "    \n",
    "    # 5. FEATURES DE BINNING\n",
    "    print(\"Criando features de binning...\")\n",
    "    \n",
    "    # Binning para funding_total_usd\n",
    "    if 'funding_total_usd' in train_fe.columns:\n",
    "        # Definir bins baseados em quantis\n",
    "        bins = [-np.inf, train_fe['funding_total_usd'].quantile(0.25), \n",
    "                train_fe['funding_total_usd'].quantile(0.5),\n",
    "                train_fe['funding_total_usd'].quantile(0.75), np.inf]\n",
    "        \n",
    "        train_fe['funding_bin'] = pd.cut(train_fe['funding_total_usd'], \n",
    "                                       bins=bins, labels=['Low', 'Med_Low', 'Med_High', 'High'])\n",
    "        test_fe['funding_bin'] = pd.cut(test_fe['funding_total_usd'], \n",
    "                                      bins=bins, labels=['Low', 'Med_Low', 'Med_High', 'High'])\n",
    "        \n",
    "        # One-hot encoding dos bins\n",
    "        funding_dummies_train = pd.get_dummies(train_fe['funding_bin'], prefix='funding')\n",
    "        funding_dummies_test = pd.get_dummies(test_fe['funding_bin'], prefix='funding')\n",
    "        \n",
    "        train_fe = pd.concat([train_fe.drop('funding_bin', axis=1), funding_dummies_train], axis=1)\n",
    "        test_fe = pd.concat([test_fe.drop('funding_bin', axis=1), funding_dummies_test], axis=1)\n",
    "    \n",
    "    # 6. POLYNOMIAL FEATURES para variáveis mais importantes\n",
    "    print(\"Criando polynomial features...\")\n",
    "    \n",
    "    important_numeric_cols = ['relationships', 'funding_total_usd', 'milestones']\n",
    "    existing_cols = [col for col in important_numeric_cols if col in train_fe.columns]\n",
    "    \n",
    "    for col in existing_cols:\n",
    "        # Quadrado\n",
    "        train_fe[f'{col}_squared'] = train_fe[col] ** 2\n",
    "        test_fe[f'{col}_squared'] = test_fe[col] ** 2\n",
    "        \n",
    "        # Log (se valores positivos)\n",
    "        if (train_fe[col] > 0).all():\n",
    "            train_fe[f'{col}_log'] = np.log1p(train_fe[col])  # log1p para evitar log(0)\n",
    "            test_fe[f'{col}_log'] = np.log1p(test_fe[col])\n",
    "    \n",
    "    print(f\"✅ Feature engineering concluído!\")\n",
    "    print(f\"   Features antes: {df_train.shape[1]}\")\n",
    "    print(f\"   Features depois: {train_fe.shape[1]}\")\n",
    "    print(f\"   Novas features: {train_fe.shape[1] - df_train.shape[1]}\")\n",
    "    \n",
    "    return train_fe, test_fe\n",
    "\n",
    "# Aplicar feature engineering\n",
    "X_train_fe, X_test_fe = criar_features_avancadas(X_train, X_test)\n",
    "\n",
    "# Garantir mesmas colunas\n",
    "common_cols = list(set(X_train_fe.columns) & set(X_test_fe.columns))\n",
    "X_train_fe = X_train_fe[common_cols]\n",
    "X_test_fe = X_test_fe[common_cols]\n",
    "\n",
    "print(f\"\\nFeatures finais: {X_train_fe.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb43371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENSEMBLE METHODS AVANÇADOS\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print(\"\\n🤝 ENSEMBLE METHODS AVANÇADOS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Dividir dados com feature engineering para validação\n",
    "X_train_fe_split, X_val_fe, y_train_fe_split, y_val_fe = train_test_split(\n",
    "    X_train_fe, y_train, test_size=0.3, random_state=42, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"📊 Divisão dos dados:\")\n",
    "print(f\"   Train FE: {X_train_fe_split.shape}\")\n",
    "print(f\"   Validation FE: {X_val_fe.shape}\")\n",
    "\n",
    "# 1. VOTING CLASSIFIER (Soft Voting)\n",
    "print(\"\\n1️⃣ Criando Voting Classifier...\")\n",
    "\n",
    "# Usar modelos otimizados se disponíveis, senão usar padrões\n",
    "try:\n",
    "    gb_model = gb_random.best_estimator_\n",
    "    rf_model = rf_random.best_estimator_\n",
    "    print(\"   ✅ Usando modelos otimizados\")\n",
    "except:\n",
    "    gb_model = GradientBoostingClassifier(random_state=42)\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    print(\"   ⚠️ Usando modelos padrões (otimização não disponível)\")\n",
    "\n",
    "voting_estimators = [\n",
    "    ('gb', gb_model),\n",
    "    ('rf', rf_model),\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter=1000, C=0.1)),\n",
    "    ('svm', SVC(probability=True, random_state=42, C=0.1)),\n",
    "    ('knn', KNeighborsClassifier(n_neighbors=7))\n",
    "]\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=voting_estimators,\n",
    "    voting='soft'  # Usa probabilidades\n",
    ")\n",
    "\n",
    "print(f\"   📝 Estimadores no ensemble: {len(voting_estimators)}\")\n",
    "\n",
    "# 2. STACKING CLASSIFIER\n",
    "print(\"\\n2️⃣ Criando Stacking Classifier...\")\n",
    "\n",
    "base_estimators = [\n",
    "    ('gb', gb_model),\n",
    "    ('rf', rf_model),\n",
    "    ('lr', LogisticRegression(random_state=42, max_iter=1000)),\n",
    "    ('svm', SVC(probability=True, random_state=42, C=0.1))\n",
    "]\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    "    cv=5,\n",
    "    stack_method='predict_proba'\n",
    ")\n",
    "\n",
    "print(f\"   📝 Base estimadores: {len(base_estimators)}\")\n",
    "print(f\"   🎯 Meta-estimador: Logistic Regression\")\n",
    "\n",
    "# 3. TREINAR E AVALIAR ENSEMBLE METHODS\n",
    "print(\"\\n3️⃣ Treinando e avaliando modelos...\")\n",
    "\n",
    "ensembles = {\n",
    "    'Voting Classifier': voting_clf,\n",
    "    'Stacking Classifier': stacking_clf,\n",
    "    'GB Otimizado': gb_model,\n",
    "    'RF Otimizado': rf_model,\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "ensemble_results = {}\n",
    "\n",
    "for name, model in ensembles.items():\n",
    "    print(f\"\\n🔧 Treinando {name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X_train_fe_split, y_train_fe_split, \n",
    "                                   cv=3, scoring='roc_auc', n_jobs=-1)  # Reduzido para 3 CV\n",
    "        \n",
    "        # Treinar modelo\n",
    "        model.fit(X_train_fe_split, y_train_fe_split)\n",
    "        \n",
    "        # Predições\n",
    "        y_pred = model.predict(X_val_fe)\n",
    "        y_pred_proba = model.predict_proba(X_val_fe)[:, 1]\n",
    "        \n",
    "        # Métricas\n",
    "        auc = roc_auc_score(y_val_fe, y_pred_proba)\n",
    "        accuracy = accuracy_score(y_val_fe, y_pred)\n",
    "        f1 = f1_score(y_val_fe, y_pred)\n",
    "        \n",
    "        ensemble_results[name] = {\n",
    "            'model': model,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'val_auc': auc,\n",
    "            'val_accuracy': accuracy,\n",
    "            'val_f1': f1\n",
    "        }\n",
    "        \n",
    "        print(f\"   📊 CV AUC: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "        print(f\"   🎯 Val AUC: {auc:.4f}\")\n",
    "        print(f\"   📈 Val Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"   ⚖️ Val F1: {f1:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Erro treinando {name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# Comparação final\n",
    "print(f\"\\n📊 COMPARAÇÃO FINAL DE MODELOS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Modelo':<20} {'AUC':<8} {'Accuracy':<10} {'F1':<8} {'CV AUC':<10}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for name, results in ensemble_results.items():\n",
    "    print(f\"{name:<20} {results['val_auc']:.4f}   {results['val_accuracy']:.4f}     {results['val_f1']:.4f}   {results['cv_mean']:.4f}\")\n",
    "\n",
    "# Melhor modelo\n",
    "if ensemble_results:\n",
    "    best_model_name = max(ensemble_results.keys(), \n",
    "                         key=lambda x: ensemble_results[x]['val_auc'])\n",
    "    best_model = ensemble_results[best_model_name]['model']\n",
    "    best_auc = ensemble_results[best_model_name]['val_auc']\n",
    "\n",
    "    print(f\"\\n🏆 MELHOR MODELO: {best_model_name}\")\n",
    "    print(f\"   🎯 AUC: {best_auc:.4f}\")\n",
    "    print(f\"   📈 Accuracy: {ensemble_results[best_model_name]['val_accuracy']:.4f}\")\n",
    "    print(f\"   ⚖️ F1-Score: {ensemble_results[best_model_name]['val_f1']:.4f}\")\n",
    "else:\n",
    "    print(\"\\n❌ Nenhum modelo foi treinado com sucesso\")\n",
    "    best_model_name = \"Gradient Boosting\"\n",
    "    best_model = gb_model\n",
    "    best_auc = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE SELECTION E ANÁLISE DE IMPORTÂNCIA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "print(\"\\n🔍 FEATURE SELECTION E ANÁLISE\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# 1. ANÁLISE DE IMPORTÂNCIA\n",
    "print(\"\\n1️⃣ Analisando importância das features...\")\n",
    "\n",
    "# Usar o melhor modelo para análise de importância\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_names = X_train_fe.columns\n",
    "    \n",
    "    # DataFrame com importâncias\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"🎯 TOP 15 FEATURES MAIS IMPORTANTES:\")\n",
    "    print(\"=\"*60)\n",
    "    for i, (_, row) in enumerate(importance_df.head(15).iterrows(), 1):\n",
    "        feature_type = \"\"\n",
    "        if any(suffix in row['feature'] for suffix in ['_squared', '_log']):\n",
    "            feature_type = \" 🔢[POLY]\"\n",
    "        elif any(suffix in row['feature'] for suffix in ['_per_', '_duration', 'total_']):\n",
    "            feature_type = \" 🔗[INTER]\"\n",
    "        elif 'funding_' in row['feature'] and any(bin_name in row['feature'] for bin_name in ['Low', 'Med', 'High']):\n",
    "            feature_type = \" 📊[BIN]\"\n",
    "        else:\n",
    "            feature_type = \" 📈[ORIG]\"\n",
    "        \n",
    "        print(f\"{i:2d}. {row['feature']:<35}: {row['importance']:.6f}{feature_type}\")\n",
    "    \n",
    "    # Análise por tipo de feature\n",
    "    print(f\"\\n📊 ANÁLISE POR TIPO DE FEATURE:\")\n",
    "    original_features = importance_df[~importance_df['feature'].str.contains('_squared|_log|_per_|_duration|total_|funding_Low|funding_Med|funding_High')]\n",
    "    poly_features = importance_df[importance_df['feature'].str.contains('_squared|_log')]\n",
    "    interaction_features = importance_df[importance_df['feature'].str.contains('_per_|_duration|total_')]\n",
    "    binning_features = importance_df[importance_df['feature'].str.contains('funding_Low|funding_Med|funding_High')]\n",
    "    \n",
    "    original_importance = original_features['importance'].sum()\n",
    "    poly_importance = poly_features['importance'].sum()\n",
    "    interaction_importance = interaction_features['importance'].sum()\n",
    "    binning_importance = binning_features['importance'].sum()\n",
    "    \n",
    "    print(f\"   📈 Features Originais: {original_importance:.1%} ({len(original_features)} features)\")\n",
    "    print(f\"   🔢 Features Polinomiais: {poly_importance:.1%} ({len(poly_features)} features)\")\n",
    "    print(f\"   🔗 Features de Interação: {interaction_importance:.1%} ({len(interaction_features)} features)\")\n",
    "    print(f\"   📊 Features de Binning: {binning_importance:.1%} ({len(binning_features)} features)\")\n",
    "    \n",
    "    # 2. FEATURE SELECTION BASEADA EM IMPORTÂNCIA\n",
    "    print(f\"\\n2️⃣ Selecionando features mais importantes...\")\n",
    "    \n",
    "    # Selecionar features que representam 95% da importância cumulativa\n",
    "    importance_df_sorted = importance_df.sort_values('importance', ascending=False)\n",
    "    cumulative_importance = importance_df_sorted['importance'].cumsum()\n",
    "    n_features_95 = (cumulative_importance <= 0.95).sum()\n",
    "    n_features_selected = max(20, min(n_features_95, len(feature_names) // 2))\n",
    "    \n",
    "    top_features = importance_df_sorted.head(n_features_selected)['feature'].tolist()\n",
    "    \n",
    "    X_train_selected = X_train_fe[top_features]\n",
    "    X_test_selected = X_test_fe[top_features]\n",
    "    \n",
    "    print(f\"   📝 Selecionadas {len(top_features)} features de {len(feature_names)}\")\n",
    "    print(f\"   📊 Representam {cumulative_importance.iloc[n_features_selected-1]:.1%} da importância total\")\n",
    "    \n",
    "    # 3. RETREINAR MODELO COM FEATURES SELECIONADAS\n",
    "    print(f\"\\n3️⃣ Retreinando modelo com features selecionadas...\")\n",
    "    \n",
    "    X_train_sel_split, X_val_sel, y_train_sel_split, y_val_sel = train_test_split(\n",
    "        X_train_selected, y_train, test_size=0.3, random_state=42, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    # Criar nova instância do melhor modelo\n",
    "    if best_model_name == 'Voting Classifier':\n",
    "        selected_model = VotingClassifier(\n",
    "            estimators=voting_estimators,\n",
    "            voting='soft'\n",
    "        )\n",
    "    elif best_model_name == 'Stacking Classifier':\n",
    "        selected_model = StackingClassifier(\n",
    "            estimators=base_estimators,\n",
    "            final_estimator=LogisticRegression(random_state=42),\n",
    "            cv=3,\n",
    "            stack_method='predict_proba'\n",
    "        )\n",
    "    else:\n",
    "        # Para modelos individuais, criar nova instância\n",
    "        if hasattr(best_model, 'get_params'):\n",
    "            params = best_model.get_params()\n",
    "            selected_model = type(best_model)(**params)\n",
    "        else:\n",
    "            selected_model = best_model\n",
    "    \n",
    "    # Treinar com features selecionadas\n",
    "    selected_model.fit(X_train_sel_split, y_train_sel_split)\n",
    "    \n",
    "    # Avaliar\n",
    "    y_pred_sel_proba = selected_model.predict_proba(X_val_sel)[:, 1]\n",
    "    y_pred_sel = selected_model.predict(X_val_sel)\n",
    "    \n",
    "    auc_selected = roc_auc_score(y_val_sel, y_pred_sel_proba)\n",
    "    accuracy_selected = accuracy_score(y_val_sel, y_pred_sel)\n",
    "    f1_selected = f1_score(y_val_sel, y_pred_sel)\n",
    "    \n",
    "    print(f\"   📊 Comparação de Performance:\")\n",
    "    print(f\"   AUC com todas as features: {best_auc:.4f}\")\n",
    "    print(f\"   AUC com features selecionadas: {auc_selected:.4f}\")\n",
    "    print(f\"   Diferença AUC: {auc_selected - best_auc:+.4f}\")\n",
    "    \n",
    "    # Escolher a melhor versão\n",
    "    if auc_selected > best_auc:\n",
    "        print(\"   ✅ Feature selection melhorou o modelo!\")\n",
    "        final_model = selected_model\n",
    "        final_X_train = X_train_selected\n",
    "        final_X_test = X_test_selected\n",
    "        final_auc = auc_selected\n",
    "        final_accuracy = accuracy_selected\n",
    "        final_f1 = f1_selected\n",
    "        features_used = len(top_features)\n",
    "    else:\n",
    "        print(\"   ✅ Modelo original é melhor, mantendo todas as features\")\n",
    "        final_model = best_model\n",
    "        final_X_train = X_train_fe\n",
    "        final_X_test = X_test_fe\n",
    "        final_auc = best_auc\n",
    "        final_accuracy = ensemble_results[best_model_name]['val_accuracy']\n",
    "        final_f1 = ensemble_results[best_model_name]['val_f1']\n",
    "        features_used = len(X_train_fe.columns)\n",
    "\n",
    "else:\n",
    "    print(\"   ⚠️ Modelo não suporta feature_importances_\")\n",
    "    \n",
    "    # Usar SelectKBest como alternativa\n",
    "    print(\"   🔄 Usando SelectKBest como alternativa...\")\n",
    "    \n",
    "    k_features = min(50, X_train_fe.shape[1] // 2)\n",
    "    selector = SelectKBest(score_func=f_classif, k=k_features)\n",
    "    \n",
    "    X_train_selected = selector.fit_transform(X_train_fe, y_train)\n",
    "    X_test_selected = selector.transform(X_test_fe)\n",
    "    \n",
    "    # Converter de volta para DataFrame\n",
    "    selected_feature_names = X_train_fe.columns[selector.get_support()]\n",
    "    X_train_selected = pd.DataFrame(X_train_selected, columns=selected_feature_names, index=X_train_fe.index)\n",
    "    X_test_selected = pd.DataFrame(X_test_selected, columns=selected_feature_names, index=X_test_fe.index)\n",
    "    \n",
    "    final_model = best_model\n",
    "    final_X_train = X_train_selected\n",
    "    final_X_test = X_test_selected\n",
    "    final_auc = best_auc\n",
    "    features_used = k_features\n",
    "    \n",
    "    print(f\"   📝 Selecionadas {k_features} features usando SelectKBest\")\n",
    "\n",
    "print(f\"\\n✅ FEATURE SELECTION CONCLUÍDA!\")\n",
    "print(f\"   🏆 Modelo final: {best_model_name}\")\n",
    "print(f\"   📊 Features utilizadas: {features_used}\")\n",
    "print(f\"   🎯 AUC final: {final_auc:.4f}\")\n",
    "\n",
    "# 4. ANÁLISE DAS FEATURES MAIS IMPACTANTES\n",
    "if hasattr(final_model, 'feature_importances_') and len(final_X_train.columns) <= 30:\n",
    "    print(f\"\\n4️⃣ TOP 10 FEATURES DO MODELO FINAL:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    final_importances = pd.DataFrame({\n",
    "        'feature': final_X_train.columns,\n",
    "        'importance': final_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    for i, (_, row) in enumerate(final_importances.head(10).iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['feature']:<30}: {row['importance']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f021bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBMISSÃO FINAL OTIMIZADA\n",
    "print(f\"\\n📝 GERANDO SUBMISSÃO FINAL OTIMIZADA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"🏆 Modelo final escolhido: {best_model_name}\")\n",
    "print(f\"📊 AUC de validação: {final_auc:.4f}\")\n",
    "print(f\"📈 Accuracy de validação: {final_accuracy:.4f}\")\n",
    "print(f\"⚖️ F1-Score de validação: {final_f1:.4f}\")\n",
    "print(f\"🔢 Features utilizadas: {features_used}\")\n",
    "\n",
    "# Treinar modelo final em TODOS os dados\n",
    "print(f\"\\n🔧 Treinando modelo final em todos os dados de treino...\")\n",
    "print(f\"   Shape dos dados finais:\")\n",
    "print(f\"   X_train: {final_X_train.shape}\")\n",
    "print(f\"   y_train: {y_train.shape}\")\n",
    "print(f\"   X_test: {final_X_test.shape}\")\n",
    "\n",
    "try:\n",
    "    final_model.fit(final_X_train, y_train)\n",
    "    print(\"✅ Modelo final treinado com sucesso!\")\n",
    "    \n",
    "    # Fazer predições no test set\n",
    "    print(\"\\n🎯 Gerando predições finais...\")\n",
    "    y_pred_final_proba = final_model.predict_proba(final_X_test)[:, 1]\n",
    "    \n",
    "    # Usar threshold otimizado (0.5 padrão, mas pode ser ajustado)\n",
    "    threshold = 0.5\n",
    "    y_pred_final = (y_pred_final_proba > threshold).astype(int)\n",
    "    \n",
    "    print(f\"   📊 Probabilidades geradas: {len(y_pred_final_proba)}\")\n",
    "    print(f\"   🎯 Threshold usado: {threshold}\")\n",
    "    print(f\"   📈 Predições binárias: {len(y_pred_final)}\")\n",
    "    \n",
    "    # Verificar distribuição das predições\n",
    "    success_rate_pred = y_pred_final.mean()\n",
    "    success_rate_train = y_train.mean()\n",
    "    \n",
    "    print(f\"\\n📊 Análise das predições:\")\n",
    "    print(f\"   Taxa de sucesso no treino: {success_rate_train:.1%}\")\n",
    "    print(f\"   Taxa de sucesso predita: {success_rate_pred:.1%}\")\n",
    "    print(f\"   Diferença: {success_rate_pred - success_rate_train:+.1%}\")\n",
    "    \n",
    "    # Estatísticas das probabilidades\n",
    "    print(f\"\\n📈 Estatísticas das probabilidades:\")\n",
    "    print(f\"   Média: {y_pred_final_proba.mean():.4f}\")\n",
    "    print(f\"   Mediana: {np.median(y_pred_final_proba):.4f}\")\n",
    "    print(f\"   Mín: {y_pred_final_proba.min():.4f}\")\n",
    "    print(f\"   Máx: {y_pred_final_proba.max():.4f}\")\n",
    "    print(f\"   Std: {y_pred_final_proba.std():.4f}\")\n",
    "    \n",
    "    # Criar submission\n",
    "    print(f\"\\n📁 Criando arquivo de submissão...\")\n",
    "    \n",
    "    # Verificar se existe coluna ID\n",
    "    if 'id' in test.columns:\n",
    "        id_col = test['id']\n",
    "        print(\"   ✅ Usando coluna 'id' do dataset original\")\n",
    "    else:\n",
    "        id_col = range(len(test))\n",
    "        print(\"   ⚠️ Criando IDs sequenciais\")\n",
    "    \n",
    "    submission_optimized = pd.DataFrame({\n",
    "        'id': id_col,\n",
    "        'labels': y_pred_final\n",
    "    })\n",
    "    \n",
    "    # Nome do arquivo com informações do modelo\n",
    "    model_short_name = best_model_name.lower().replace(' ', '_').replace('classifier', 'clf')\n",
    "    filename = f'submission_optimized_{model_short_name}_auc_{final_auc:.4f}.csv'\n",
    "    \n",
    "    # Salvar arquivo\n",
    "    submission_optimized.to_csv(filename, index=False)\n",
    "    print(f\"✅ Submissão salva em: {filename}\")\n",
    "    \n",
    "    # Informações do arquivo\n",
    "    print(f\"\\n📋 INFORMAÇÕES DA SUBMISSÃO:\")\n",
    "    print(f\"   📄 Arquivo: {filename}\")\n",
    "    print(f\"   📊 Linhas: {len(submission_optimized)}\")\n",
    "    print(f\"   📋 Colunas: {list(submission_optimized.columns)}\")\n",
    "    print(f\"   🎯 Valores únicos em 'labels': {sorted(submission_optimized['labels'].unique())}\")\n",
    "    \n",
    "    print(\"\\n📈 Distribuição das predições:\")\n",
    "    value_counts = submission_optimized['labels'].value_counts().sort_index()\n",
    "    for label, count in value_counts.items():\n",
    "        percentage = count / len(submission_optimized) * 100\n",
    "        label_name = \"Fracasso\" if label == 0 else \"Sucesso\"\n",
    "        print(f\"   {label} ({label_name}): {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Mostrar primeiras linhas\n",
    "    print(f\"\\n📝 Primeiras 10 linhas da submissão:\")\n",
    "    print(submission_optimized.head(10))\n",
    "    \n",
    "    print(f\"\\n🎉 SUBMISSÃO OTIMIZADA CONCLUÍDA!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"🏆 Modelo: {best_model_name}\")\n",
    "    print(f\"📊 AUC esperado: {final_auc:.4f}\")\n",
    "    print(f\"📈 Accuracy esperada: {final_accuracy:.4f}\")\n",
    "    print(f\"⚖️ F1-Score esperado: {final_f1:.4f}\")\n",
    "    print(f\"🔢 Features: {features_used}\")\n",
    "    print(f\"📁 Arquivo: {filename}\")\n",
    "    print(f\"🚀 Melhoria estimada: +{final_auc - 0.830:.3f} AUC vs modelo base\")\n",
    "    print(f\"💡 Pronto para upload no Kaggle!\")\n",
    "    \n",
    "    # Comparar com resultados anteriores se disponível\n",
    "    if 'resultados' in globals():\n",
    "        print(f\"\\n📊 COMPARAÇÃO COM MODELOS ANTERIORES:\")\n",
    "        print(\"-\"*50)\n",
    "        for nome, resultado in resultados.items():\n",
    "            old_auc = resultado['roc_auc']\n",
    "            improvement = final_auc - old_auc\n",
    "            print(f\"   {nome}: {old_auc:.4f} → {final_auc:.4f} ({improvement:+.4f})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro ao treinar modelo final: {str(e)}\")\n",
    "    print(\"🔄 Tentando com modelo de backup...\")\n",
    "    \n",
    "    # Modelo de backup simples\n",
    "    backup_model = GradientBoostingClassifier(random_state=42)\n",
    "    backup_model.fit(X_train_fe, y_train)\n",
    "    y_pred_backup = backup_model.predict_proba(X_test_fe)[:, 1]\n",
    "    \n",
    "    submission_backup = pd.DataFrame({\n",
    "        'id': test['id'] if 'id' in test.columns else range(len(test)),\n",
    "        'labels': (y_pred_backup > 0.5).astype(int)\n",
    "    })\n",
    "    \n",
    "    backup_filename = 'submission_backup_gb.csv'\n",
    "    submission_backup.to_csv(backup_filename, index=False)\n",
    "    print(f\"✅ Submissão de backup salva em: {backup_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
